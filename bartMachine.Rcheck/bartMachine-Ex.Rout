
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "bartMachine"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('bartMachine')
Loading required package: rJava
Loading required package: car
Loading required package: randomForest
randomForest 4.6-7
Type rfNews() to see new features/changes/bug fixes.
Loading required package: missForest
Welcome to BART v1.0

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("bart_machine_get_posterior")
> ### * bart_machine_get_posterior
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_machine_get_posterior
> ### Title: Get Full Posterior Distribution
> ### Aliases: bart_machine_get_posterior
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 26.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 39.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 52.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 68.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 17.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 98.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 48.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 128.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 208.1/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 32.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 112.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 191.9/1398.3MB
done building BART in 0.74 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get posterior distribution
> posterior = bart_machine_get_posterior(bart_machine, X)
> print(posterior$y_hat)
  [1]  9.651772  8.536283 15.691508  1.240693 11.130162 10.511042 12.142678
  [8] 10.959338 16.777042 15.677587 14.145402 20.701113 18.927663 16.873143
 [15]  8.062749 18.674825 22.693462 20.259431 18.489922 15.564250  6.883763
 [22] 19.761053 20.902663 20.811721 10.475086 21.601081  8.519686 12.865034
 [29] 15.986630 12.715730 10.698475 18.456593 13.125710  7.041079 20.857663
 [36] 19.326504 14.448912  8.438589 13.330853 14.491826 13.340263  9.584095
 [43]  9.828983 18.845808 12.218948 16.988500 18.047009 10.479409 18.910766
 [50] 16.493864 11.449074 18.834161 15.752467 14.751269 15.255245 12.704272
 [57] 21.114509 17.915932 11.485412 17.872929  7.184664 21.282697  6.482708
 [64] 14.542008 18.472294  8.108659  6.785910 14.813391 14.997746  6.536639
 [71] 19.433102 19.873599  5.154209 18.823259  7.850524 15.116342 18.110545
 [78] 12.286076 11.732591  8.809957  4.131272 22.705104 20.909105 16.569293
 [85] 17.342314 10.788059 11.147009 18.984369 24.778964 12.919937 17.710361
 [92] 15.349527  4.436219 10.027595 14.891716 10.777711 18.725176 15.900340
 [99] 17.968839 12.206739  8.795011 11.454194 16.920220 11.342947 13.560842
[106]  8.433897 24.212968 14.848856 10.792540 10.412838 16.726152 15.049472
[113] 21.700876 16.696980 17.066468 10.663973  9.718569 13.535260 12.578974
[120] 15.721558  9.710771 14.724270 22.837661  7.833864 19.650705 15.763701
[127] 14.323029 17.902745  9.346364  8.854406 16.404050 18.055155 10.909673
[134] 14.653126  9.581528 20.826662  8.731892 13.219828 14.713481 10.971939
[141] 20.236374 19.205128 17.173932 14.763826 15.691201 16.907582 13.662762
[148] 17.939134 17.808009  9.108158 15.697865 13.667842 16.638548 19.743182
[155] 16.380751  6.676024 13.215448 19.335102 18.767561 16.140594  9.952121
[162] 12.565649 19.150020 13.638132 15.587443 15.713271 11.040480 11.312163
[169] 13.461731 10.491270 18.824908 12.046070 19.558718 23.428484 24.010538
[176] 14.599759  9.745365 17.443615 15.956695 15.185559 24.892025  9.234993
[183] 10.894955 14.342624 13.636521 10.527924 15.107304  2.765498 17.010049
[190] 17.566721 21.895438  8.359474 14.889371 16.302330  5.434323 15.850202
[197] 21.004924 19.263019 16.309309  8.919001
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> #Classification example
> 
> #get data and only use 2 factors
> data(iris)
> iris2 = iris[51:150,]
> iris2$Species = factor(iris2$Species)
> 
> #build BART classification model
> bart_machine = build_bart_machine(iris2[ ,1 : 4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 60.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 108/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 145.9/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 193.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 240.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 287.7/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 335/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 382.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 429.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 473.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 71.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 118.7/1398.3MB
done building BART in 0.339 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get posterior distribution
> posterior = bart_machine_get_posterior(bart_machine, iris2[ ,1 : 4])
> print(posterior$y_hat)
  [1] 0.08078216 0.07191559 0.23407610 0.04730730 0.12461854 0.04811419
  [7] 0.17350456 0.04770388 0.06233642 0.05288811 0.05425988 0.05352979
 [13] 0.04843226 0.09734708 0.02964831 0.04701418 0.07539083 0.03031792
 [19] 0.15361455 0.03240556 0.61606124 0.03265748 0.35467605 0.07498893
 [25] 0.04248773 0.05177674 0.17292950 0.61948591 0.08518131 0.03325187
 [31] 0.03534232 0.03472170 0.02691204 0.52673528 0.08247040 0.12486782
 [37] 0.09615031 0.08103051 0.02565912 0.03931528 0.05041465 0.07047868
 [43] 0.03280127 0.04953208 0.03511247 0.02492694 0.02992435 0.03983912
 [49] 0.04518437 0.03106223 0.97764020 0.92008140 0.98449618 0.94914415
 [55] 0.98642596 0.98450279 0.41845390 0.95402491 0.95477635 0.97860655
 [61] 0.90880763 0.95395663 0.97765941 0.92736003 0.95760750 0.96243532
 [67] 0.93225243 0.97685528 0.98857191 0.42592247 0.98056577 0.88578877
 [73] 0.98160914 0.82079262 0.97216759 0.93642174 0.74154170 0.77363675
 [79] 0.98618972 0.74238026 0.97652907 0.96381733 0.98781005 0.42824601
 [85] 0.59574436 0.98801462 0.97494175 0.92133309 0.68481238 0.96284310
 [91] 0.97956083 0.94528378 0.92008140 0.98160958 0.97747826 0.96358723
 [97] 0.92003109 0.94687351 0.96542946 0.84166306
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("bart_machine_num_cores")
> ### * bart_machine_num_cores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_machine_num_cores
> ### Title: Get Number of Cores Used by BART
> ### Aliases: bart_machine_num_cores
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> bart_machine_num_cores()
[1] 1
> 
> 
> 
> cleanEx()
> nameEx("bart_predict_for_test_data")
> ### * bart_predict_for_test_data
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_predict_for_test_data
> ### Title: Predict for Test Data with Known Outcomes
> ### Aliases: bart_predict_for_test_data
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 400 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##split into train and test
> train_X = X[1 : 200, ]
> test_X = X[201 : 400, ]
> train_y = y[1 : 200]
> test_y = y[201 : 400]
> 
> ##build BART regression model
> bart_machine = build_bart_machine(train_X, train_y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 86.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 254.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 328.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 412.6/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 42.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 116.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 200.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 284.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 359/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 442.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 69.9/1398.3MB
done building BART in 0.387 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #explore performance on test data
> oos_perf = bart_predict_for_test_data(bart_machine, test_X, test_y)
> print(oos_perf$rmse)
[1] 1.468004
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("build_bart_machine")
> ### * build_bart_machine
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: build_bart_machine
> ### Title: Build a BART Model
> ### Aliases: build_bart_machine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ##regression example
> 
> ##generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 87.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 254.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 328.9/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 412.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 44.6/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 128.3/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 202.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 286.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 370.2/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 444.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 81.9/1398.3MB
done building BART in 0.364 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> summary(bart_machine)
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.4 secs on 1 core, 50 trees, 250 burn in and 1000 post. samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.75191 

in-sample statistics:
 L1 = 94.1 
 L2 = 70.14 
 rmse = 0.59 
 Pseudo-Rsq = 0.985
p-val for shapiro-wilk test of normality of residuals: 0.32328 
p-val for zero-mean noise: 0.30562 

> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> ##Build another BART regression model
> bart_machine = build_bart_machine(X,y, num_trees = 200, num_burn_in = 500,
+ num_iterations_after_burn_in =1000)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1500  mem: 347.4/1398.3MB
Sampling M_1/200 iter 200/1500  mem: 220.2/1398.3MB
Sampling M_1/200 iter 300/1500  mem: 74.2/1398.3MB
Sampling M_1/200 iter 400/1500  mem: 400.1/1398.3MB
Sampling M_1/200 iter 500/1500  mem: 260.2/1398.3MB
Sampling M_1/200 iter 600/1500  mem: 129.4/1398.3MB
Sampling M_1/200 iter 700/1500  mem: 448.6/1398.3MB
Sampling M_1/200 iter 800/1500  mem: 325.7/1398.3MB
Sampling M_1/200 iter 900/1500  mem: 201.3/1398.3MB
Sampling M_1/200 iter 1000/1500  mem: 525.7/1398.3MB
Sampling M_1/200 iter 1100/1500  mem: 394.6/1398.3MB
Sampling M_1/200 iter 1200/1500  mem: 271.1/1398.3MB
Sampling M_1/200 iter 1300/1500  mem: 159.5/1398.3MB
Sampling M_1/200 iter 1400/1500  mem: 481/1398.3MB
Sampling M_1/200 iter 1500/1500  mem: 360.3/1398.3MB
done building BART in 1.922 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #Destroy BART model
> destroy_bart_machine(bart_machine)
> 
> ##Classification example
> 
> #get data and only use 2 factors
> data(iris)
> iris2 = iris[51:150,]
> iris2$Species = factor(iris2$Species)
> 
> #build BART classification model
> bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 57.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 103.5/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 149.3/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 195.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 241/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 286.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 332.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 378.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 424.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 34/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 79.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 125.7/1398.3MB
done building BART in 0.286 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...