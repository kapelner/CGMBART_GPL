
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "bartMachine"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> options(pager = "console")
> library('bartMachine')
Loading required package: rJava
Loading required package: car
Loading required package: randomForest
randomForest 4.6-7
Type rfNews() to see new features/changes/bug fixes.
Loading required package: missForest
Welcome to BART v1.0

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("bart_machine_get_posterior")
> ### * bart_machine_get_posterior
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_machine_get_posterior
> ### Title: Get Full Posterior Distribution
> ### Aliases: bart_machine_get_posterior
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 27.1/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 40/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 52.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 68.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 17.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 98.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 49.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 129.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 208.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 34.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 114/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 193.6/1398.3MB
done building BART in 0.718 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get posterior distribution
> posterior = bart_machine_get_posterior(bart_machine, X)
> print(posterior$y_hat)
  [1]  9.842944  8.575336 16.168152  1.954689 10.462204 11.020777 12.036214
  [8] 11.077581 16.186438 15.957609 14.832530 20.901641 18.987939 16.884639
 [15]  8.173918 18.973985 22.904271 20.183066 18.411216 15.884646  6.431483
 [22] 20.940451 21.453049 21.501031 10.425015 22.179504  8.923984 12.345046
 [29] 15.909973 12.713132  9.913924 18.351782 12.195405  7.754846 20.601696
 [36] 19.510245 13.864179  8.062179 13.058802 14.337296 13.082054  9.611266
 [43] 10.235444 19.204506 12.697893 16.806101 18.242363 11.031139 19.172068
 [50] 16.002510 11.112576 19.914401 15.958142 14.654561 14.693114 11.950859
 [57] 20.307997 17.956323 11.665223 17.633019  6.858457 20.876370  6.207196
 [64] 14.249652 17.752504  8.451778  7.061463 14.704598 15.565489  7.095637
 [71] 19.252075 20.318577  4.809143 18.901585  8.138073 15.052925 18.441682
 [78] 12.565440 11.331784  8.038736  3.609549 22.476813 20.098509 16.727139
 [85] 17.572901 10.881233 11.070409 17.959833 25.309599 12.673000 17.898582
 [92] 15.487537  4.128571 10.752816 14.259944 10.870225 18.898966 16.405561
 [99] 18.771543 12.084189  8.701721 10.602080 17.759261 11.755999 13.486430
[106]  8.552313 23.684783 14.872862 10.849361 10.435609 17.025657 15.398313
[113] 21.100202 17.654811 16.747691 10.863570 10.212934 13.739622 12.288746
[120] 13.582361 10.414498 14.816193 22.997243  7.892021 19.297608 15.912912
[127] 14.180541 18.227059  9.385636  9.147709 16.356582 17.974141 10.596637
[134] 14.984606  8.983118 21.009635  9.049741 13.585634 15.032140 11.274405
[141] 19.633635 19.363572 17.909865 14.246054 16.715481 16.369958 14.393706
[148] 17.703047 17.116058  9.131565 15.861416 13.457911 17.225311 18.863119
[155] 18.767566  5.952100 13.283700 19.468272 18.309152 16.177142  9.296396
[162] 13.020111 19.782954 14.283412 16.145526 15.743507 11.374098 11.014885
[169] 12.980187 10.278451 18.871439 11.466827 19.560686 23.751318 24.291730
[176] 15.549518  9.604126 17.055167 15.652853 15.294378 25.961797  8.706019
[183] 10.318791 14.625144 13.580509 10.613005 14.828511  2.853574 17.524595
[190] 17.456157 22.088246  8.091497 14.642136 16.706256  5.508409 15.878946
[197] 19.595913 19.529933 16.525926  8.774511
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> #Classification example
> 
> #get data and only use 2 factors
> data(iris)
> iris2 = iris[51:150,]
> iris2$Species = factor(iris2$Species)
> 
> #build BART classification model
> bart_machine = build_bart_machine(iris2[ ,1 : 4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 60.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 97.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 144.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 191.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 238.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 285.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 332.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 378.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 425.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 469.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 70.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 117.2/1398.3MB
done building BART in 0.339 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get posterior distribution
> posterior = bart_machine_get_posterior(bart_machine, iris2[ ,1 : 4])
> print(posterior$y_hat)
  [1] 0.08572895 0.07622372 0.21745749 0.04287752 0.13623998 0.05339447
  [7] 0.16757674 0.04595975 0.06008322 0.05207992 0.04591097 0.06038511
 [13] 0.04375861 0.09527343 0.02591588 0.04946621 0.08176761 0.03164100
 [19] 0.17388586 0.02966885 0.61805646 0.03800120 0.32796119 0.08020307
 [25] 0.04181915 0.05532879 0.16992335 0.59983231 0.09512441 0.02834524
 [31] 0.02988818 0.02906000 0.02850149 0.54209218 0.08427464 0.12376233
 [37] 0.10385019 0.08118711 0.02375639 0.03637743 0.04871556 0.07301889
 [43] 0.03300742 0.03958366 0.03843096 0.02243855 0.02843217 0.03836037
 [49] 0.03813696 0.03119117 0.97306629 0.92347281 0.98330254 0.95267735
 [55] 0.98478862 0.97903919 0.41977718 0.95763247 0.96098607 0.97247927
 [61] 0.90793299 0.96052312 0.97371146 0.91530267 0.94237631 0.95485150
 [67] 0.93638205 0.96530563 0.98128395 0.41947422 0.97596322 0.85630176
 [73] 0.97725741 0.81645214 0.96791288 0.94144969 0.75699760 0.76206359
 [79] 0.98521294 0.75415775 0.97602029 0.95902317 0.98651992 0.46074333
 [85] 0.60915153 0.98346233 0.96914535 0.92507101 0.69873419 0.96471117
 [91] 0.97322431 0.93278919 0.92347281 0.97603240 0.96901967 0.95369033
 [97] 0.91699862 0.94845097 0.95820995 0.84747121
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("bart_machine_num_cores")
> ### * bart_machine_num_cores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_machine_num_cores
> ### Title: Get Number of Cores Used by BART
> ### Aliases: bart_machine_num_cores
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> bart_machine_num_cores()
[1] 1
> 
> 
> 
> cleanEx()
> nameEx("bart_predict_for_test_data")
> ### * bart_predict_for_test_data
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: bart_predict_for_test_data
> ### Title: Predict for Test Data with Known Outcomes
> ### Aliases: bart_predict_for_test_data
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 400 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##split into train and test
> train_X = X[1 : 200, ]
> test_X = X[201 : 400, ]
> train_y = y[1 : 200]
> test_y = y[201 : 400]
> 
> ##build BART regression model
> bart_machine = build_bart_machine(train_X, train_y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 95.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 169.3/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 252.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 335.8/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 419/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 51.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 125.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 208.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 292/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 366/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 449.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 88/1398.3MB
done building BART in 0.367 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #explore performance on test data
> oos_perf = bart_predict_for_test_data(bart_machine, test_X, test_y)
> print(oos_perf$rmse)
[1] 1.336378
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("build_bart_machine")
> ### * build_bart_machine
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: build_bart_machine
> ### Title: Build a BART Model
> ### Aliases: build_bart_machine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ##regression example
> 
> ##generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 96.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 253.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 336.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 410.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 44.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 127.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 201.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 285.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 368.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 443.1/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 81.3/1398.3MB
done building BART in 0.364 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> summary(bart_machine)
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.4 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.72947 

in-sample statistics:
 L1 = 96.23 
 L2 = 77.07 
 rmse = 0.62 
 Pseudo-Rsq = 0.9835
p-val for shapiro-wilk test of normality of residuals: 0.61569 
p-val for zero-mean noise: 0.09867 

> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> ##Build another BART regression model
> bart_machine = build_bart_machine(X,y, num_trees = 200, num_burn_in = 500,
+ num_iterations_after_burn_in =1000)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1500  mem: 347/1398.3MB
Sampling M_1/200 iter 200/1500  mem: 220.9/1398.3MB
Sampling M_1/200 iter 300/1500  mem: 82.8/1398.3MB
Sampling M_1/200 iter 400/1500  mem: 408.4/1398.3MB
Sampling M_1/200 iter 500/1500  mem: 269.3/1398.3MB
Sampling M_1/200 iter 600/1500  mem: 138.7/1398.3MB
Sampling M_1/200 iter 700/1500  mem: 456.8/1398.3MB
Sampling M_1/200 iter 800/1500  mem: 333.9/1398.3MB
Sampling M_1/200 iter 900/1500  mem: 209.7/1398.3MB
Sampling M_1/200 iter 1000/1500  mem: 87.4/1398.3MB
Sampling M_1/200 iter 1100/1500  mem: 411.2/1398.3MB
Sampling M_1/200 iter 1200/1500  mem: 297.7/1398.3MB
Sampling M_1/200 iter 1300/1500  mem: 176.8/1398.3MB
Sampling M_1/200 iter 1400/1500  mem: 507.5/1398.3MB
Sampling M_1/200 iter 1500/1500  mem: 386.6/1398.3MB
done building BART in 1.904 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #Destroy BART model
> destroy_bart_machine(bart_machine)
> 
> ##Classification example
> 
> #get data and only use 2 factors
> data(iris)
> iris2 = iris[51:150,]
> iris2$Species = factor(iris2$Species)
> 
> #build BART classification model
> bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 57.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 103.3/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 149/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 194.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 240.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 286.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 331.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 377.6/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 423.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 33.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 79.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 125.6/1398.3MB
done building BART in 0.288 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##get estimated probabilities
> phat = bart_machine$p_hat_train
> ##look at in-sample confusion matrix
> bart_machine$confusion_matrix
                  predicted versicolor predicted virginica model errors
actual versicolor                47.00                3.00         0.06
actual virginica                  3.00               47.00         0.06
use errors                        0.06                0.06         0.06
> 
> #destroy BART model 
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("build_bart_machine_cv")
> ### * build_bart_machine_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: build_bart_machine_cv
> ### Title: Build BART-CV
> ### Aliases: build_bart_machine_cv
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine_cv = build_bart_machine_cv(X, y)
  BART CV try: k: 2 nu, q: 3, 0.9 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 35.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 99.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 163.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 227.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 300.7/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 364.8/1398.3MB
done building BART in 0.305 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.8/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 100.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 164.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 228.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 292.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 366.1/1398.3MB
done building BART in 0.306 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.8/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 414.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 100.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 164.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 228.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 302.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 366.6/1398.3MB
done building BART in 0.307 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.3/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 341.6/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 405.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 28/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 165.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 229.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 294.1/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 358.3/1398.3MB
done building BART in 0.308 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 341.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 406.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 165.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 229.8/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 303.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 367.6/1398.3MB
done building BART in 0.308 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 2 nu, q: 3, 0.9 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 287.5/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 105.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 371.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 199.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 465.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 293/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 130/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 395.8/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 230.6/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 501.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 340.8/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 180.2/1398.3MB
done building BART in 1.37 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 281.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.6/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 382.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 212/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 154.3/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 426.7/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 264.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 535.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 376.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 206.4/1398.3MB
done building BART in 1.369 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 280.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 111.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 381.8/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 211.2/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 50.9/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 323.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 153/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 425.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 264.1/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 535.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 365.2/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 204.9/1398.3MB
done building BART in 1.362 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 282.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.6/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 375.6/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 204.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 476.4/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 306.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 145.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 408.6/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 247.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 520/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 358.5/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 188/1398.3MB
done building BART in 1.365 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 384.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 203.7/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 476.1/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 315.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 144.6/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 417.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 255.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 529/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 358.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 197.2/1398.3MB
done building BART in 1.41 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 2 nu, q: 3, 0.99 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 339.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 412/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 37.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 237.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 310.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 374.3/1398.3MB
done building BART in 0.308 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.8/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 339.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 412.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 100.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 173.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 237.2/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 301/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 364.8/1398.3MB
done building BART in 0.302 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 238.8/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 302.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 366.5/1398.3MB
done building BART in 0.302 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 39.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 103/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 166.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 230.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 304/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 367.9/1398.3MB
done building BART in 0.302 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 339.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 412.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 100/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 173.1/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 237/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 301/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 364.9/1398.3MB
done building BART in 0.303 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 2 nu, q: 3, 0.99 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 104.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 369.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 188.1/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 462.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 293.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 121.7/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 387.5/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 223/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 484.5/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 324.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 164.7/1398.3MB
done building BART in 1.373 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 288.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.2/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 381.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 212.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 472.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 316.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 146.7/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 418.5/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 248.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 519.2/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 350.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 181.8/1398.3MB
done building BART in 1.351 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 281.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.2/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 382.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 212.5/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 473.7/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 315.6/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 146.3/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 417.8/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 247.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 518.9/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 358.9/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 189.1/1398.3MB
done building BART in 1.356 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.6/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 383.8/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 204.5/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 475.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 308.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 138.4/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 409.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 249/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 520.2/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 351.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 191.5/1398.3MB
done building BART in 1.36 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 384.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 206.2/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 477.3/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 317.9/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 148.1/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 419.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 259.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 522.5/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 362/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 191.7/1398.3MB
done building BART in 1.36 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 2 nu, q: 10, 0.75 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.8/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 347.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 411.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 172.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 245/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 308.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 380.9/1398.3MB
done building BART in 0.307 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 73.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 146.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 209.8/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 273.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 345.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 409.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 43.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 107.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 170.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 243.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 306.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 370.3/1398.3MB
done building BART in 0.307 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 137.8/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 210.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 273.9/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 346.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 409.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 35.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 107.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 171.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 234.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 307.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 371.2/1398.3MB
done building BART in 0.307 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.3/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 274.5/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 347.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 410.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 108.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 172.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 245.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 309.1/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 372.8/1398.3MB
done building BART in 0.31 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.1/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.8/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.5/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 348.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 412/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 35.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 173/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 237.1/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 310.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 374.2/1398.3MB
done building BART in 0.309 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 2 nu, q: 10, 0.75 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 286.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.8/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 379.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 206.7/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 481.9/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 310.1/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 136.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 413.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 238/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 511.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 349.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 187.2/1398.3MB
done building BART in 1.386 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 384.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 326.1/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 154/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 428.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 264.4/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 536.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 375.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 213.1/1398.3MB
done building BART in 1.375 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 386.3/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.5/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 316.5/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 154.2/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 427.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 266/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 539.6/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 368.2/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 204.9/1398.3MB
done building BART in 1.374 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 386/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 204.6/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 478.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 316.6/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 154.2/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 419.7/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 256.2/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 529.9/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 367.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 205/1398.3MB
done building BART in 1.39 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 377.1/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 205.1/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 478.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 316.9/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 144.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 419.1/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 255.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 520.9/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 358.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 195.5/1398.3MB
done building BART in 1.374 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 3, 0.9 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.6/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.8/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 349.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 37.3/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.6/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 238.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 312.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 376.4/1398.3MB
done building BART in 0.313 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.1/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 341.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 406/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 102.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 166.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 303.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 367.9/1398.3MB
done building BART in 0.305 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.6/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.9/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 342.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 37.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.1/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 303.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 376.7/1398.3MB
done building BART in 0.309 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 342.6/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 37.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 102.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 166.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 304/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 368.2/1398.3MB
done building BART in 0.308 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 77.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 141.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.8/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 279/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 352.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416.7/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 102.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 176/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 240.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 304.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 378.1/1398.3MB
done building BART in 0.311 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 3, 0.9 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 286.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 114.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 380.8/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 206.9/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 473.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 311.5/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 138.3/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 415.1/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 248.6/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 521/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 359.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 197.6/1398.3MB
done building BART in 1.392 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 280.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 120.2/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 391.3/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 220.6/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 60.7/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 162.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 436.2/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 273.3/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 112/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 383.8/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 223.1/1398.3MB
done building BART in 1.39 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 282.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 111.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 383.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 60.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 333.1/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 162.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 434.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 282.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 120.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 393.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 232.1/1398.3MB
done building BART in 1.418 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.6/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 385.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.1/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.9/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 164.3/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 428.6/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 266.2/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 539.2/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 378.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 215.4/1398.3MB
done building BART in 1.375 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.5/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 385.6/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.6/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.4/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 154.6/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 427.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 265.8/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 539.4/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 377.8/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 215.3/1398.3MB
done building BART in 1.391 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 3, 0.99 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.6/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 111.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 312.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 376.9/1398.3MB
done building BART in 0.304 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 341.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 405.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38.4/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 102.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 166.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.8/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 303.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 367.9/1398.3MB
done building BART in 0.305 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.9/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 342.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38.3/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 102.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 303.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 377/1398.3MB
done building BART in 0.308 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 138.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.9/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 100.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 164.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 228.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 302/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 366.2/1398.3MB
done building BART in 0.306 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 340.8/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 414.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 101.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 238.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 302.7/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 376.1/1398.3MB
done building BART in 0.309 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 3, 0.99 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 286.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 379.3/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 206.6/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 481.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 310.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 147.3/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 414.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 248.3/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 520.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 359.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 197.7/1398.3MB
done building BART in 1.383 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 281.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 121/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 392.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 61.7/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.7/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 164/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 437.1/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 274.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 114.4/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 385.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 225.4/1398.3MB
done building BART in 1.413 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 291.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 121.4/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 392.6/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 61.4/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 333.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 172.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 445.2/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 283.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 122.3/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 394.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 233.8/1398.3MB
done building BART in 1.398 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.4/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 385.6/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.1/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.3/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 163.7/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 427.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 266.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 540.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 378.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 216.1/1398.3MB
done building BART in 1.388 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 285.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.8/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 387.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 215.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 53.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 327.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 165.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 439.2/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 276.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 541.3/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 378.9/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 216.9/1398.3MB
done building BART in 1.383 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 10, 0.75 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 147.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 348.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 411.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 44.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 108.6/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 181.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 245.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 309.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 382.3/1398.3MB
done building BART in 0.311 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 147.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 211.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 275.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 348.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 412.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 44.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 108.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 172.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 245.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 309.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 382.7/1398.3MB
done building BART in 0.309 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.1/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.1/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 349.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 173.2/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 237.2/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 310.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 374.4/1398.3MB
done building BART in 0.311 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 349.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 311.5/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 375.6/1398.3MB
done building BART in 0.311 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 238.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 311.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 376.2/1398.3MB
done building BART in 0.31 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 3 nu, q: 10, 0.75 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 287.5/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 114.2/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 380.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 207.2/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 483/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 311.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 146.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 414.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 248.1/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 521.2/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 359.2/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 197.3/1398.3MB
done building BART in 1.414 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 385.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 222.7/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 61.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 326.6/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 164.6/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 439/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 275/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 114.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 386.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 224.4/1398.3MB
done building BART in 1.39 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 282.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 120.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 392.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.2/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 59.6/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 333/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 171/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 444.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 282.3/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 120.4/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 384.4/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 222.1/1398.3MB
done building BART in 1.388 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 111.7/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 384.8/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 324.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 162.2/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 435.6/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 263.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 537.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 376.4/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 213.5/1398.3MB
done building BART in 1.405 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.2/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 387.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.1/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 316.3/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 153.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 427.8/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 264.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 539.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 367.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 204.4/1398.3MB
done building BART in 1.404 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 3, 0.9 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 350.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 414.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 46.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 312/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 385.4/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.1/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 38/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 111.4/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 239.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 313.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 377.5/1398.3MB
done building BART in 0.311 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351.8/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 46.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 111.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 184.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 249/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 322.5/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 386.8/1398.3MB
done building BART in 0.315 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 150.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 288.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 352.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 47.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 112/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 185.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 249.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 313.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 387.3/1398.3MB
done building BART in 0.315 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 350.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 414.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 182.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 246.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 311.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 384.6/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 3, 0.9 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 286.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.9/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 388.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.9/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 319.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 155/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 422.3/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 256.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 538.6/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 376/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 214/1398.3MB
done building BART in 1.427 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 282.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 121/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 393.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.7/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 61/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 171.9/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 445.6/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 282.2/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 130/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 402.5/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 240.9/1398.3MB
done building BART in 1.398 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 121.5/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 394.3/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 222.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 60.7/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 172.1/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 445.8/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 283.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 122/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 395.7/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 233.2/1398.3MB
done building BART in 1.395 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.4/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 387.1/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.6/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.7/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 326/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 163.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 437.8/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 274.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 112.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 386.4/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 224/1398.3MB
done building BART in 1.396 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 286.6/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 114.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 389.1/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 215.5/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52.4/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 327.4/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 155.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 430.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 267/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 541.9/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 378.9/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 215.3/1398.3MB
done building BART in 1.421 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 3, 0.99 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 150.1/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 47.4/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 111.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 176/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 249.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 313.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 387.3/1398.3MB
done building BART in 0.313 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 350.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 36.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.1/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 311.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 385.2/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.4/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 350.8/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 183.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 312/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 385.4/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 46.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.2/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 248.8/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 313.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 377.6/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.3/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 278.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 352.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416.6/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 37.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 111.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 175.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 249.1/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 313.5/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 377.9/1398.3MB
done building BART in 0.314 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 3, 0.99 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 288.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 114/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 389.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 207.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 483.2/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 320.7/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 156.4/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 424/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 257.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 530.6/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 377.9/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 215.3/1398.3MB
done building BART in 1.404 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 292.7/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 122.8/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 394.9/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 222.9/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 70.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 345.2/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 183.5/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 448.7/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 293.6/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 131.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 404.3/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 243.1/1398.3MB
done building BART in 1.404 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 285.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 122.7/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 395.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 223.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 61.5/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.6/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 172.9/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 446/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 284.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 122.1/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 395.8/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 233.3/1398.3MB
done building BART in 1.393 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.2/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 111.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 385/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 50.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 324.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 161.9/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 435.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 274/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 111.4/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 385.7/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 223.1/1398.3MB
done building BART in 1.394 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 111.9/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 386.2/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.3/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.1/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.8/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 162.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 437.5/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 274.4/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 111.3/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 385.6/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 222.7/1398.3MB
done building BART in 1.402 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 10, 0.75 m: 50 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 276.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 349.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 413.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.3/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 182.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 246.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 320.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 384.4/1398.3MB
done building BART in 0.313 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 148.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 212.8/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 350.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 414.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.7/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 183.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 321/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 385.2/1398.3MB
done building BART in 0.316 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 75.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 213.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 415.3/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 45.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 109.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 183.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 247.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 311.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 385.4/1398.3MB
done building BART in 0.315 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 149.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 287.5/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 351.8/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 46.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 184.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 248.8/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 322.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 386.8/1398.3MB
done building BART in 0.316 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 76.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 150.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 214.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 279/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 352.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 416.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 46.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 110.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 174.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 248.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 312.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 386.4/1398.3MB
done building BART in 0.316 sec 

burning and aggregating chains from all threads... done

  BART CV try: k: 5 nu, q: 10, 0.75 m: 200 
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 288.5/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 114.7/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 382/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 208.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 484.9/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 312/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 147.9/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 425/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 257.9/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 531/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 369.5/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 206.3/1398.3MB
done building BART in 1.418 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 290.7/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 120.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 392.4/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 220.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 59.8/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 334.1/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 171.1/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 445.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 281.7/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 119.4/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 391.9/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 240.3/1398.3MB
done building BART in 1.402 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 283.3/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 121.3/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 394/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 221.4/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 60.2/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 333/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 171.1/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 443.9/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 282.2/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 119.8/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 393.5/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 231.6/1398.3MB
done building BART in 1.411 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 284.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 112.8/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 386.8/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 213.5/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 51.4/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 325.7/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 163/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 437.4/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 274.4/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 539.5/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 386/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 215/1398.3MB
done building BART in 1.401 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/200 iter 100/1250  mem: 285.9/1398.3MB
Sampling M_1/200 iter 200/1250  mem: 113.1/1398.3MB
Sampling M_1/200 iter 300/1250  mem: 387.5/1398.3MB
Sampling M_1/200 iter 400/1250  mem: 214.8/1398.3MB
Sampling M_1/200 iter 500/1250  mem: 52/1398.3MB
Sampling M_1/200 iter 600/1250  mem: 326.9/1398.3MB
Sampling M_1/200 iter 700/1250  mem: 163.8/1398.3MB
Sampling M_1/200 iter 800/1250  mem: 438.7/1398.3MB
Sampling M_1/200 iter 900/1250  mem: 275.5/1398.3MB
Sampling M_1/200 iter 1000/1250  mem: 112.7/1398.3MB
Sampling M_1/200 iter 1100/1250  mem: 387.1/1398.3MB
Sampling M_1/200 iter 1200/1250  mem: 224/1398.3MB
done building BART in 1.394 sec 

burning and aggregating chains from all threads... done

  BART CV win: k: 3 nu, q: 3, 0.99 m: 50 
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 94.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 167.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 249.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 332/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 414.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 52.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 135.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 208.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 290.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 373.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 455.7/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 98.9/1398.3MB
done building BART in 0.364 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #information about cross-validated model
> summary(bart_machine_cv)
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.4 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.96186 

in-sample statistics:
 L1 = 113.78 
 L2 = 104.12 
 rmse = 0.72 
 Pseudo-Rsq = 0.9777
p-val for shapiro-wilk test of normality of residuals: 0.74343 
p-val for zero-mean noise: 0.43655 

> 
> #destroy BART model
> destroy_bart_machine(bart_machine_cv)
> 
> 
> 
> cleanEx()
> nameEx("calc_credible_intervals")
> ### * calc_credible_intervals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: calc_credible_intervals
> ### Title: Calculate Credible Intervals
> ### Aliases: calc_credible_intervals
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 94.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 167.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 250.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 332.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 415.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 43.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 126/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 208.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 291/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 373.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 446.8/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 90/1398.3MB
done building BART in 0.373 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get credible interval
> cred_int = calc_credible_intervals(bart_machine, X)
> print(head(cred_int))
     ci_lower_bd ci_upper_bd
[1,]  7.91035326   10.941885
[2,]  7.42908712   10.722502
[3,] 14.32071725   18.120755
[4,]  0.04424348    2.877386
[5,]  9.65463757   12.640020
[6,]  9.33107178   12.788854
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("calc_prediction_intervals")
> ### * calc_prediction_intervals
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: calc_prediction_intervals
> ### Title: Calculate Prediction Intervals
> ### Aliases: calc_prediction_intervals
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 93.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 167/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 250/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 323.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 406.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 42.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 116.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 199.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 282.4/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 356.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 439.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 70.2/1398.3MB
done building BART in 0.357 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get prediction interval
> pred_int = calc_prediction_intervals(bart_machine, X)
> print(head(pred_int))
     pi_lower_bd pi_upper_bd
[1,]   7.3868115   11.850349
[2,]   6.3817640   10.958060
[3,]  13.7435238   18.883438
[4,]  -0.3958554    4.250723
[5,]   8.2221788   12.704530
[6,]   8.5182436   13.170671
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("check_bart_error_assumptions")
> ### * check_bart_error_assumptions
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check_bart_error_assumptions
> ### Title: Check BART Error Assumptions
> ### Aliases: check_bart_error_assumptions
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 300 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 121.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 241.7/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 352.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 20/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 131/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 242/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 362.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 473.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 134.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 245.6/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 356.7/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 477.1/1398.3MB
done building BART in 0.488 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #check error diagnostics
> check_bart_error_assumptions(bart_machine)
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("cov_importance_test")
> ### * cov_importance_test
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: cov_importance_test
> ### Title: Importance Test for Covariate(s) of Interest
> ### Aliases: cov_importance_test
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ##regression example
> 
> ##generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 87.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 171.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 256.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 331/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 415.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 36/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 120.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 195.1/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 279.2/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 354.1/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 438.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 64/1398.3MB
done building BART in 0.364 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##now test if X[, 1] affects Y nonparametrically under the BART model assumptions
> cov_importance_test(bart_machine, covariates = c(1))
BART test for importance of covariate(s): X1 
..................................................
..................................................

p_val =  0 
> ## note the plot and the printed p-value
> 
> ##destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("destroy_bart_machine")
> ### * destroy_bart_machine
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: destroy_bart_machine
> ### Title: Destroy BART Model in Java
> ### Aliases: destroy_bart_machine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ##Generate Friedman Data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model and destroy it 
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 91.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 176.5/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 252.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 337.5/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 413.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 38.6/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 114.2/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 199.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 274.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 359.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 435.5/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 65.8/1398.3MB
done building BART in 0.436 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##should be called when object is no longer needed 
> ##and before potentially removing the object from R
> destroy_bart_machine(bart_machine) 
> 
> 
> 
> 
> cleanEx()
> nameEx("dummify_data")
> ### * dummify_data
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: dummify_data
> ### Title: Dummify Design Matrix
> ### Aliases: dummify_data
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate data
> set.seed(11)
> x1 = rnorm(20)
> x2 = as.factor(ifelse(x1 > 0, "A", "B"))
> x3 = runif(20)
> X = data.frame(x1,x2,x3)
> #dummify data
> X_dummified = dummify_data(X)
> print(X_dummified)
            x1        x3 x2_A x2_B
1  -0.59103110 0.2474559    0    1
2   0.02659437 0.2150112    1    0
3  -1.51655310 0.4936738    0    1
4  -1.36265335 0.6534460    0    1
5   1.17848916 0.3290258    1    0
6  -0.93415132 0.8638878    0    1
7   1.32360565 0.6377899    1    0
8   0.62491779 0.0137806    1    0
9  -0.04572296 0.5291648    0    1
10 -1.00412058 0.8343630    0    1
11 -0.82843324 0.5028559    0    1
12 -0.34835173 0.5977608    0    1
13 -1.53829340 0.4255951    0    1
14 -0.25556525 0.3122046    0    1
15 -1.14994503 0.2219272    0    1
16  0.01232697 0.4434262    1    0
17 -0.22296954 0.4125241    0    1
18  0.88777165 0.8157026    1    0
19 -0.59215528 0.1626589    0    1
20 -0.65571812 0.5969834    0    1
> 
> 
> 
> cleanEx()
> nameEx("get_sigsqs")
> ### * get_sigsqs
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: get_sigsqs
> ### Title: Get Posterior Error Variance Estimates
> ### Aliases: get_sigsqs
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 300 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 128.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 241.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 363.7/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 475.9/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 128.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 241.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 354.3/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 467.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 122.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 235.9/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 349/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 462/1398.3MB
done building BART in 0.594 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get posterior sigma^2's after burn-in and plot
> sigsqs = get_sigsqs(bart_machine, plot_hist = TRUE)
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("get_var_counts_over_chain")
> ### * get_var_counts_over_chain
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: get_var_counts_over_chain
> ### Title: Get the Variable Inclusion Counts
> ### Aliases: get_var_counts_over_chain
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 10
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y, num_trees = 20)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/20 iter 100/1250  mem: 41.6/1398.3MB
Sampling M_1/20 iter 200/1250  mem: 79.5/1398.3MB
Sampling M_1/20 iter 300/1250  mem: 107.9/1398.3MB
Sampling M_1/20 iter 400/1250  mem: 145.8/1398.3MB
Sampling M_1/20 iter 500/1250  mem: 174.2/1398.3MB
Sampling M_1/20 iter 600/1250  mem: 202.6/1398.3MB
Sampling M_1/20 iter 700/1250  mem: 240.5/1398.3MB
Sampling M_1/20 iter 800/1250  mem: 268.9/1398.3MB
Sampling M_1/20 iter 900/1250  mem: 306.8/1398.3MB
Sampling M_1/20 iter 1000/1250  mem: 335.2/1398.3MB
Sampling M_1/20 iter 1100/1250  mem: 373.1/1398.3MB
Sampling M_1/20 iter 1200/1250  mem: 401.5/1398.3MB
done building BART in 0.166 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #get variable inclusion counts
> var_counts = get_var_counts_over_chain(bart_machine)
> print(var_counts)
        X1 X2 X3 X4 X5 X6 X7 X8 X9 X10
   [1,]  7  7  8  4  4  1  0  1  1   0
   [2,]  6  7  8  4  5  2  0  1  1   0
   [3,]  6  7  8  4  6  1  0  1  1   0
   [4,]  6  7  8  4  6  2  0  1  2   0
   [5,]  6  7  8  4  5  2  1  2  3   0
   [6,]  6  7  8  4  5  1  0  3  2   0
   [7,]  6  7  9  3  5  1  1  3  2   1
   [8,]  6  7  8  3  4  2  0  3  2   0
   [9,]  6  7  8  3  5  2  0  3  2   0
  [10,]  6  6  8  3  5  1  0  3  1   1
  [11,]  6  7  8  3  4  1  0  1  2   3
  [12,]  6  6  9  3  4  1  0  2  1   2
  [13,]  6  6  9  3  5  1  0  3  1   1
  [14,]  6  6  9  3  4  2  0  3  1   1
  [15,]  7  5  7  3  3  1  2  3  1   1
  [16,]  7  6  7  3  3  2  2  2  1   1
  [17,]  8  6  7  3  3  2  1  3  1   0
  [18,]  8  7  8  4  3  1  1  2  1   1
  [19,]  8  6  8  3  4  1  1  2  1   1
  [20,]  9  6  8  3  3  1  2  2  2   1
  [21,]  8  6  7  3  5  1  2  3  2   0
  [22,]  8  7  7  4  4  1  1  3  1   1
  [23,]  9  6  7  4  4  2  1  3  1   2
  [24,]  9  6  7  5  4  2  0  1  1   1
  [25,]  8  5  8  4  4  2  0  2  1   1
  [26,]  8  5  8  3  3  2  0  3  1   1
  [27,]  8  5  7  3  3  2  1  4  1   0
  [28,]  9  5  7  3  3  2  0  3  1   0
  [29,]  8  5  7  4  3  1  0  3  2   0
  [30,]  8  5  7  4  3  1  0  3  2   0
  [31,]  8  5  7  4  3  1  0  4  2   0
  [32,]  8  5  7  3  4  1  1  4  1   0
  [33,]  7  4  7  3  4  1  1  2  1   0
  [34,]  9  4  8  4  4  2  0  2  1   0
  [35,]  8  4  9  4  4  2  0  2  1   0
  [36,]  8  5  9  6  4  2  0  2  1   0
  [37,]  8  5  9  3  4  1  0  3  1   0
  [38,]  8  6  9  3  4  1  1  4  1   0
  [39,]  8  4 10  3  5  2  0  4  1   0
  [40,]  8  5  9  3  4  1  3  4  1   0
  [41,]  8  6  9  3  3  1  2  5  1   1
  [42,]  7  4 10  4  3  1  3  4  1   0
  [43,]  7  5  9  3  3  3  2  3  1   0
  [44,]  7  6  9  3  3  1  2  3  1   0
  [45,]  7  6  9  3  3  1  2  2  2   1
  [46,]  7  6 10  4  3  1  3  2  1   0
  [47,]  7  6  8  4  3  2  4  2  1   0
  [48,]  7  5  8  5  3  2  2  4  1   0
  [49,]  7  5  8  3  3  2  2  5  1   0
  [50,]  7  5  8  3  3  3  2  4  1   0
  [51,]  7  6  8  3  4  2  2  4  1   0
  [52,]  7  6  8  4  4  1  2  4  1   0
  [53,]  7  7  8  3  3  1  2  4  1   0
  [54,]  7  7  9  3  3  1  2  5  1   0
  [55,]  7  8  9  3  3  1  2  5  1   0
  [56,]  8  6  9  3  3  1  2  6  2   0
  [57,]  9  5  9  3  4  1  2  3  1   1
  [58,]  8  5  8  3  4  1  1  4  2   1
  [59,]  9  6  8  4  3  1  1  3  2   0
  [60,]  8  6  8  4  4  1  1  2  2   0
  [61,]  8  6  8  4  3  1  1  2  2   0
  [62,]  8  5  8  4  3  1  1  2  1   0
  [63,]  8  5  9  5  3  1  1  2  1   1
  [64,]  9  5  8  5  3  1  1  2  1   1
  [65,]  8  4  8  4  3  1  3  2  1   1
  [66,]  6  4  8  4  3  1  2  2  3   1
  [67,]  6  4  8  4  4  3  1  3  1   1
  [68,]  6  4  8  4  4  1  1  3  1   1
  [69,]  6  4  8  4  4  2  1  3  1   1
  [70,]  7  4  9  5  3  1  1  3  1   1
  [71,]  6  4  8  6  3  2  1  3  1   2
  [72,]  6  5  9  5  3  1  1  3  2   2
  [73,]  6  4 11  5  4  1  0  4  3   0
  [74,]  6  4  9  6  4  1  0  4  3   0
  [75,]  6  4  9  5  5  1  0  4  2   1
  [76,]  7  4  9  5  4  1  1  3  2   1
  [77,]  7  4  9  5  5  1  1  3  1   0
  [78,]  7  4  9  5  4  1  0  3  1   1
  [79,]  7  5  9  5  4  1  2  3  0   0
  [80,]  6  5  9  5  3  1  2  3  0   1
  [81,]  6  4  9  6  3  2  1  3  0   0
  [82,]  6  5  9  5  3  1  0  3  1   0
  [83,]  6  5  9  4  3  1  0  4  0   0
  [84,]  6  5  8  4  3  2  0  4  1   0
  [85,]  7  4  7  4  3  4  0  3  0   0
  [86,]  8  4  7  5  4  1  0  3  0   1
  [87,]  7  4  7  5  3  1  0  2  0   1
  [88,]  8  4  7  5  3  1  0  2  0   1
  [89,]  7  5  8  5  3  1  1  2  0   0
  [90,]  6  5  8  5  3  1  1  2  0   0
  [91,]  6  3  7  4  4  1  2  2  1   1
  [92,]  6  3  7  4  5  1  0  2  0   2
  [93,]  6  3  7  4  5  2  0  2  0   2
  [94,]  7  3  7  4  4  2  2  2  0   2
  [95,]  8  3  7  4  5  3  2  1  1   2
  [96,]  8  3  7  4  4  3  2  1  1   2
  [97,]  7  3  7  5  4  3  1  1  1   2
  [98,]  8  3  7  6  3  4  1  2  1   2
  [99,]  8  4  8  5  3  3  1  3  1   2
 [100,]  9  4  7  6  3  3  1  2  1   2
 [101,]  9  5  8  5  4  2  1  1  0   2
 [102,]  9  5  8  4  4  3  2  1  0   2
 [103,] 11  4  7  4  3  4  0  1  0   1
 [104,] 11  5  8  4  4  3  1  1  0   1
 [105,] 11  5  8  4  4  3  0  1  1   2
 [106,] 11  5  8  5  5  3  0  1  1   2
 [107,] 11  5 10  6  3  3  0  2  1   1
 [108,] 10  6 10  5  3  3  1  2  0   2
 [109,]  9  6 10  5  3  4  1  1  0   1
 [110,]  9  5  9  5  3  3  2  1  0   1
 [111,]  9  5  8  6  4  2  2  1  1   1
 [112,] 10  5  8  5  3  1  2  1  1   1
 [113,] 10  6  8  5  3  2  1  1  0   1
 [114,] 10  6  8  5  3  2  1  1  0   1
 [115,] 10  6  8  5  3  2  2  1  0   1
 [116,] 10  5  8  5  3  2  1  1  0   0
 [117,]  9  5  8  5  4  2  1  1  0   0
 [118,]  8  4  9  6  4  3  1  1  0   0
 [119,]  8  5  9  5  4  3  1  2  1   0
 [120,]  8  5 10  5  4  4  0  2  0   0
 [121,]  7  5 11  5  4  3  0  1  0   0
 [122,]  7  5 10  6  4  3  0  1  0   1
 [123,]  8  6  9  6  5  2  0  1  0   1
 [124,]  8  6  9  6  4  1  1  2  0   1
 [125,]  8  7 10  7  5  1  0  2  1   0
 [126,]  9  7 10  7  5  1  0  2  0   1
 [127,] 10  7  9  6  5  1  0  2  1   2
 [128,] 10  6  9  6  5  1  0  3  2   0
 [129,] 10  6  9  7  6  1  0  2  1   2
 [130,]  9  8  7  8  7  1  0  1  1   0
 [131,]  9  7  8  6  5  1  0  2  2   0
 [132,]  8  6  7  6  6  1  0  2  1   1
 [133,]  7  7  7  6  6  1  1  2  1   1
 [134,]  6  7  7  5  7  1  0  1  1   2
 [135,]  6  7  7  5  6  1  0  1  1   1
 [136,]  6  7  7  5  6  1  0  1  1   1
 [137,]  6  7  8  5  6  2  0  0  1   0
 [138,]  7  7  7  5  5  2  1  0  1   0
 [139,]  6  7  7  5  5  2  2  0  0   0
 [140,]  6  7  7  5  5  2  2  0  0   0
 [141,]  6  7  7  6  5  1  1  0  0   0
 [142,]  6  7  9  6  6  1  1  0  1   0
 [143,]  6  7 10  6  6  2  0  0  1   0
 [144,]  6  7  9  5  6  2  0  0  1   0
 [145,]  6  7  8  6  7  3  0  1  0   2
 [146,]  6  7 10  5  7  2  0  1  0   0
 [147,]  6  7  8  4  6  2  0  1  0   0
 [148,]  6  8  7  4  5  2  0  1  0   0
 [149,]  6  6  7  4  6  2  0  1  0   0
 [150,]  7  6  7  4  6  2  0  1  0   1
 [151,]  6  7  7  4  5  2  0  1  0   1
 [152,]  6  7  6  4  5  1  0  1  0   1
 [153,]  6  8  6  4  4  1  1  1  0   0
 [154,]  6  7  6  4  5  1  1  1  0   0
 [155,]  6  7  7  5  4  1  0  1  0   0
 [156,]  8  7  7  5  4  1  0  1  0   0
 [157,]  7  7  7  5  4  1  0  2  0   1
 [158,]  7  7  8  5  4  1  1  1  0   1
 [159,]  7  7  8  4  5  1  1  1  0   1
 [160,]  8  8  8  4  5  1  1  1  1   1
 [161,]  7  9  8  4  4  2  0  3  2   1
 [162,]  7  8  8  4  5  3  0  1  1   1
 [163,]  8  8  8  4  5  3  1  1  0   1
 [164,]  7  8  7  4  7  2  0  2  0   0
 [165,]  7  8  7  4  6  3  1  2  0   0
 [166,]  7  8  8  4  4  1  1  2  1   0
 [167,]  7  7  8  4  3  1  1  3  1   0
 [168,]  7  7  8  4  3  1  1  3  0   3
 [169,]  6  7  8  4  4  1  2  2  0   1
 [170,]  6  7  8  4  3  1  0  2  0   3
 [171,]  6  7  7  4  3  2  0  2  2   3
 [172,]  6  7  7  4  4  2  0  3  1   1
 [173,]  7  6  7  4  4  2  0  3  2   1
 [174,]  7  6  7  5  3  2  0  2  2   1
 [175,]  7  7  7  4  3  2  0  3  1   1
 [176,]  6  7  7  3  4  2  0  3  2   1
 [177,]  6  7  7  3  4  4  1  3  0   2
 [178,]  6  6  7  3  5  3  1  2  1   2
 [179,]  8  6  7  3  5  3  1  2  1   1
 [180,]  8  7  7  3  5  2  1  3  0   1
 [181,]  9  7  8  3  5  2  2  2  0   2
 [182,]  8  7  7  4  5  3  1  3  3   1
 [183,]  8  7  7  3  6  3  1  3  2   1
 [184,]  8  7  8  3  5  2  2  2  1   1
 [185,] 10  6  6  4  7  1  0  3  1   1
 [186,] 10  5  6  4  7  1  0  1  2   1
 [187,]  9  5  6  4  7  2  0  1  2   1
 [188,]  9  5  6  3  7  2  0  1  1   1
 [189,]  9  5  6  3  6  3  0  1  1   1
 [190,]  8  7  6  3  5  2  1  2  2   1
 [191,]  9  4  8  3  5  2  1  3  3   1
 [192,]  9  5  8  4  5  2  0  3  2   1
 [193,]  9  5  8  4  5  3  0  1  1   1
 [194,]  8  4  7  4  6  2  0  2  1   1
 [195,]  7  5  7  4  7  2  0  1  2   1
 [196,]  7  6  7  4  6  2  0  2  2   1
 [197,]  8  4  6  4  7  1  1  1  2   1
 [198,]  8  3  6  5  6  1  2  1  1   1
 [199,]  8  3  7  6  5  2  2  1  1   1
 [200,]  8  4  7  6  5  1  2  1  3   1
 [201,]  8  5  7  6  5  1  2  1  2   1
 [202,]  8  4  8  6  5  1  2  1  1   3
 [203,]  8  4  8  6  6  1  2  2  1   2
 [204,]  9  5  7  5  5  1  2  2  1   2
 [205,]  9  4  7  6  5  1  2  2  2   3
 [206,]  9  4  7  5  5  1  2  1  2   2
 [207,] 10  4  6  5  5  3  2  1  1   2
 [208,] 10  4  6  6  4  2  1  1  3   3
 [209,]  9  5  9  4  4  3  1  2  1   1
 [210,]  9  5  8  5  5  2  0  2  1   1
 [211,]  9  5  8  4  6  1  0  1  2   3
 [212,]  8  4  9  4  5  1  0  1  2   3
 [213,]  8  4  9  4  6  1  1  1  2   3
 [214,]  9  4 10  4  5  1  0  1  1   4
 [215,]  9  4 10  4  6  2  0  1  1   3
 [216,]  8  4  9  4  5  3  0  1  2   5
 [217,]  8  4  9  4  5  2  0  2  2   4
 [218,]  8  4  9  4  4  1  1  1  2   2
 [219,]  7  4  9  5  4  1  0  1  2   2
 [220,]  7  5  8  4  5  1  0  1  2   2
 [221,]  7  5  8  4  5  1  0  2  2   2
 [222,]  7  4  8  4  6  1  0  2  2   2
 [223,]  8  4  8  5  5  1  0  1  2   2
 [224,]  7  4  8  5  4  1  1  1  2   3
 [225,]  7  5  7  5  4  1  0  1  1   2
 [226,]  7  4  7  5  4  1  0  1  1   1
 [227,]  8  4  7  5  4  1  0  2  1   1
 [228,]  8  5  7  4  4  2  0  2  1   1
 [229,]  7  5  7  4  4  2  0  2  1   1
 [230,]  7  4  7  5  4  2  2  2  1   1
 [231,]  7  4  7  6  4  3  1  1  1   1
 [232,]  7  5  8  5  5  3  0  1  1   1
 [233,]  7  5  7  5  5  3  0  1  1   1
 [234,]  7  4  7  5  5  1  0  1  2   1
 [235,]  7  4  7  5  4  1  0  2  1   1
 [236,]  7  4  7  5  4  1  0  2  1   2
 [237,]  8  5  7  5  4  1  0  1  1   2
 [238,]  8  4  7  5  4  1  0  1  1   1
 [239,]  8  4  6  4  4  2  0  2  1   1
 [240,]  8  4  7  4  4  2  0  1  2   1
 [241,]  8  5  7  4  4  1  0  1  2   2
 [242,] 10  3  7  4  5  1  0  1  1   1
 [243,]  8  5  7  4  4  1  0  1  1   1
 [244,]  9  5  7  5  4  1  0  1  1   1
 [245,]  9  5  7  4  4  1  0  1  1   1
 [246,]  8  5  7  4  5  1  0  1  1   1
 [247,]  8  5  7  4  5  1  0  1  1   1
 [248,]  8  5  7  5  4  1  0  1  1   1
 [249,]  8  5  8  4  4  1  0  1  2   1
 [250,]  8  5  8  4  4  1  0  1  1   1
 [251,]  8  4  8  4  5  1  0  1  2   2
 [252,]  8  3  8  4  5  1  0  1  2   1
 [253,]  8  4  8  5  5  1  0  1  2   1
 [254,]  8  4  8  4  4  1  0  1  2   1
 [255,]  7  3  8  4  5  1  0  1  2   2
 [256,]  7  3  8  4  5  1  0  2  2   2
 [257,]  8  4  8  4  6  1  1  1  2   1
 [258,]  8  4  8  4  5  1  2  2  1   1
 [259,]  8  4  8  4  6  2  1  1  1   1
 [260,]  7  5  8  4  6  1  1  1  1   2
 [261,]  7  6  8  4  6  1  0  1  1   2
 [262,]  7  6  8  4  5  2  0  1  1   2
 [263,]  8  4  8  4  5  2  0  1  4   2
 [264,]  8  3  8  6  5  3  0  2  3   2
 [265,]  7  3  8  5  5  2  1  1  2   2
 [266,]  7  3  8  4  5  1  2  3  2   3
 [267,]  7  4  8  4  5  2  1  1  2   3
 [268,]  8  3  8  4  4  2  1  1  1   4
 [269,]  8  3  8  4  4  2  2  2  1   3
 [270,]  8  3  8  4  3  2  2  2  1   3
 [271,]  8  3  9  4  4  2  2  3  1   3
 [272,]  8  3  9  5  4  1  3  1  1   3
 [273,]  7  3  9  5  4  1  1  2  1   5
 [274,]  7  3  9  4  5  1  2  2  1   3
 [275,]  7  3 10  4  6  2  2  1  1   2
 [276,]  8  3  9  4  5  1  2  3  1   2
 [277,]  7  3  9  6  5  3  2  2  1   2
 [278,]  8  3  9  5  5  3  2  2  1   2
 [279,]  7  3  9  5  4  4  2  1  1   3
 [280,]  6  3 10  5  4  4  1  0  2   3
 [281,]  6  4 10  5  4  3  1  0  1   3
 [282,]  6  3 10  5  4  3  1  1  1   3
 [283,]  6  3 11  5  4  2  1  0  1   3
 [284,]  6  3  9  6  4  2  1  2  1   0
 [285,]  6  3  9  5  4  2  1  2  1   0
 [286,]  6  3  9  5  4  2  1  2  1   0
 [287,]  6  3  9  5  4  3  1  1  1   0
 [288,]  7  3  9  5  4  3  1  1  1   0
 [289,]  7  4  9  4  4  3  1  1  1   0
 [290,]  7  4 10  4  4  2  1  0  1   0
 [291,]  7  4 10  5  4  2  2  0  1   0
 [292,]  7  4 11  5  4  2  2  0  1   0
 [293,]  7  3  9  6  4  2  1  0  1   1
 [294,]  7  3  9  5  4  2  1  1  1   1
 [295,]  7  4  9  5  4  1  1  0  1   1
 [296,]  7  4 10  5  4  1  1  0  1   1
 [297,]  7  4 10  5  5  1  1  0  1   2
 [298,]  7  4 10  5  5  1  2  0  1   1
 [299,]  8  4 10  6  4  1  1  0  1   2
 [300,]  8  4 10  5  4  1  1  0  1   1
 [301,]  8  4 10  7  4  1  1  0  1   0
 [302,]  8  4  9  6  4  1  1  0  3   0
 [303,]  8  5  9  7  4  1  1  0  3   0
 [304,]  8  4 11  7  4  1  1  0  3   0
 [305,]  8  4 11  7  4  1  1  0  3   0
 [306,]  9  4 10  5  4  1  1  0  3   0
 [307,]  9  4 10  6  4  1  1  1  2   0
 [308,]  8  4 10  6  4  1  0  2  2   1
 [309,]  8  4  9  6  3  1  2  2  2   2
 [310,]  8  4  9  5  5  1  2  1  2   3
 [311,]  8  4  9  5  5  1  2  1  2   2
 [312,]  8  4  9  6  4  1  1  0  2   4
 [313,]  8  4  9  5  4  2  1  0  2   3
 [314,]  8  3  9  5  4  2  3  0  2   2
 [315,]  8  3  9  5  4  2  4  0  1   1
 [316,]  8  4  9  5  4  1  2  1  1   1
 [317,]  8  3 10  5  5  2  2  1  1   0
 [318,]  9  3 10  6  4  2  2  0  1   0
 [319,]  8  3 10  6  5  2  1  0  2   0
 [320,]  8  3 10  7  3  1  2  0  1   0
 [321,]  9  3  9  7  4  1  2  0  1   0
 [322,]  9  3  9  8  4  1  1  0  1   0
 [323,]  7  4 10  8  4  2  1  0  1   0
 [324,]  7  4  9  7  4  2  0  2  1   0
 [325,]  7  4  9  7  3  1  0  0  2   1
 [326,]  8  4  9  7  3  1  0  0  1   1
 [327,]  8  4 10  7  3  2  0  0  1   0
 [328,]  8  3 10  7  5  1  0  0  1   0
 [329,]  7  3 10  7  5  1  0  0  2   1
 [330,]  7  3 10  7  5  1  0  0  2   1
 [331,]  7  3 11  7  5  1  1  1  2   1
 [332,]  8  3 10  7  5  1  3  1  2   0
 [333,]  7  4 10  6  6  1  1  1  4   0
 [334,]  7  4  9  8  6  1  1  0  3   0
 [335,]  7  4  9  8  6  1  2  1  2   0
 [336,]  7  4  9  8  6  1  1  0  2   0
 [337,]  7  4 10  7  7  1  1  0  1   0
 [338,]  8  4 10  7  7  1  1  0  3   0
 [339,]  8  4 11  6  7  1  1  0  2   0
 [340,]  9  4 10  7  6  1  2  0  2   0
 [341,]  7  4 10  7  6  2  2  0  1   0
 [342,]  7  4 11  8  4  2  1  0  1   1
 [343,]  6  4 10  8  4  2  1  0  1   3
 [344,]  6  3 10  7  4  4  1  1  1   1
 [345,]  6  3  8  7  5  3  1  1  1   1
 [346,]  6  3  8  7  6  4  1  1  1   1
 [347,]  8  2  8  7  6  3  1  1  1   1
 [348,]  8  2  8  6  6  2  1  1  1   1
 [349,]  8  2  8  6  7  2  0  2  1   1
 [350,]  7  2  8  7  6  2  1  2  1   1
 [351,]  7  2  8  7  5  3  0  1  1   1
 [352,]  7  2  8  7  5  3  0  1  2   1
 [353,]  7  2  8  6  5  2  0  1  2   2
 [354,]  8  2  9  5  5  2  0  1  2   2
 [355,]  7  2  9  5  5  2  0  1  2   1
 [356,]  7  2  8  5  5  2  0  2  2   1
 [357,]  7  2  8  5  5  2  0  2  2   1
 [358,]  7  2  7  6  5  2  0  2  2   1
 [359,]  7  2  7  6  5  2  0  2  1   1
 [360,]  6  3  7  6  5  2  0  2  1   1
 [361,]  6  2  8  5  5  2  1  2  1   1
 [362,]  6  2  7  5  4  2  1  2  2   1
 [363,]  7  2  6  5  4  1  1  1  1   1
 [364,]  7  2  6  5  5  1  0  1  1   1
 [365,]  7  2  7  5  5  1  0  1  1   1
 [366,]  8  2  7  5  3  1  0  1  2   1
 [367,]  9  2  8  5  4  1  0  2  0   1
 [368,]  7  2  7  4  5  1  0  2  0   1
 [369,]  8  3  7  4  4  2  1  1  0   1
 [370,]  8  2  7  4  5  2  0  1  0   1
 [371,]  7  2  8  4  3  2  0  3  0   1
 [372,]  7  2  8  4  3  2  0  2  0   2
 [373,]  7  3  8  5  3  1  0  2  0   1
 [374,]  7  3  8  5  3  1  0  2  0   0
 [375,]  7  3 11  5  3  1  0  0  0   0
 [376,]  8  4 10  4  3  1  0  0  0   0
 [377,]  9  4  9  3  3  1  0  1  0   1
 [378,]  8  4 10  3  3  1  0  1  2   0
 [379,]  7  4  9  3  3  2  0  0  2   2
 [380,]  7  4  7  3  3  3  1  0  1   1
 [381,]  6  5  9  3  5  2  1  0  0   1
 [382,]  6  7  8  3  4  1  2  0  2   1
 [383,]  6  7  8  3  6  1  1  0  1   1
 [384,]  6  6  8  3  6  2  0  0  2   1
 [385,]  6  6  8  4  5  2  1  0  1   0
 [386,]  6  6  8  5  5  2  1  0  1   0
 [387,]  5  6  8  3  6  2  1  1  1   1
 [388,]  6  5  8  3  7  2  1  0  1   1
 [389,]  6  5  8  3  6  1  0  0  2   1
 [390,]  6  5  8  4  6  1  0  0  1   0
 [391,]  7  6  8  4  6  1  0  0  2   0
 [392,]  7  6  8  4  6  1  0  0  2   0
 [393,]  5  5  7  5  6  1  1  0  4   0
 [394,]  5  6  7  4  6  1  1  1  3   0
 [395,]  6  6  7  5  6  1  1  1  2   0
 [396,]  6  6  7  4  5  1  1  0  2   1
 [397,]  7  7  7  6  6  1  1  0  1   0
 [398,]  7  5  7  5  8  1  3  0  1   1
 [399,]  7  5  8  6  6  2  2  0  2   1
 [400,]  6  5  8  5  6  2  2  0  1   1
 [401,]  6  5  9  4  6  1  1  0  0   2
 [402,]  6  6  8  5  5  1  1  0  1   1
 [403,]  5  6  7  5  5  1  1  0  1   1
 [404,]  6  7  7  5  5  1  2  1  0   0
 [405,]  5  7  6  8  6  1  2  1  0   0
 [406,]  5  6  8  5  6  2  1  0  0   0
 [407,]  6  7  7  6  6  1  0  0  1   0
 [408,]  6  7  6  6  6  1  1  0  0   1
 [409,]  7  6  7  6  5  2  1  0  0   0
 [410,]  7  5  7  6  7  1  1  0  1   0
 [411,]  7  5  8  6  6  1  1  0  0   1
 [412,]  7  5  7  5  5  1  0  2  0   0
 [413,]  7  6  9  6  5  1  0  1  1   0
 [414,]  7  5  8  6  5  1  0  0  1   0
 [415,]  7  5  7  4  5  3  1  1  0   0
 [416,]  8  5  7  6  5  1  1  1  1   1
 [417,]  7  5  6  6  5  1  0  1  4   1
 [418,]  7  5  7  7  5  1  0  0  2   2
 [419,]  7  5  7  7  5  1  0  1  3   2
 [420,]  7  5  7  7  5  2  0  2  3   2
 [421,]  7  5  8  6  5  2  0  1  3   3
 [422,]  7  5  9  5  5  2  0  2  3   3
 [423,]  7  5  9  5  6  2  0  1  3   4
 [424,]  7  5  9  5  6  2  1  1  3   3
 [425,]  7  5 10  6  5  2  3  1  4   1
 [426,]  7  5  8  4  6  2  2  1  4   2
 [427,]  7  5  7  5  6  1  2  2  3   2
 [428,]  7  5  8  5  6  1  4  0  2   1
 [429,]  6  5  8  5  6  1  4  1  1   1
 [430,]  7  5  6  5  6  1  4  0  1   2
 [431,]  8  5  6  5  5  1  4  1  1   1
 [432,]  8  6  6  4  5  1  3  0  1   1
 [433,]  7  5  6  5  5  1  2  0  0   2
 [434,]  6  6  6  5  5  2  2  1  1   1
 [435,]  6  6  5  4  5  3  1  1  2   2
 [436,]  6  5  6  4  5  1  3  1  1   1
 [437,]  6  5  5  4  7  1  1  0  0   1
 [438,]  6  5  5  4  7  1  1  0  0   2
 [439,]  6  5  5  4  6  1  1  0  0   2
 [440,]  6  5  5  5  6  1  3  0  0   1
 [441,]  8  4  5  4  6  2  2  0  0   1
 [442,]  7  4  5  5  6  2  2  0  1   2
 [443,]  7  4  6  4  6  2  2  0  1   2
 [444,]  6  3  6  4  7  2  1  1  4   1
 [445,]  6  4  6  4  6  2  1  1  3   1
 [446,]  6  5  7  4  6  2  1  1  0   1
 [447,]  6  4  7  4  6  1  1  1  1   2
 [448,]  7  5  8  3  6  1  0  1  0   0
 [449,]  6  4  9  3  6  2  0  1  0   0
 [450,]  6  5  9  3  6  2  0  0  0   1
 [451,]  6  6  9  4  6  2  0  0  0   0
 [452,]  6  5 10  4  7  2  0  0  0   0
 [453,]  6  4  9  4  7  2  0  0  0   0
 [454,]  6  4  8  4  7  2  1  0  0   0
 [455,]  6  4  8  3  7  1  1  1  0   0
 [456,]  7  4  8  4  5  1  0  1  2   0
 [457,]  6  3  8  4  6  2  0  0  2   0
 [458,]  6  3  7  5  5  1  0  0  1   0
 [459,]  6  3  7  7  3  1  0  0  0   0
 [460,]  6  3  7  5  3  1  1  0  0   0
 [461,]  7  3  7  5  3  1  2  0  0   0
 [462,]  7  3  8  5  4  1  2  0  0   0
 [463,]  8  3  8  6  3  1  2  0  0   1
 [464,]  8  3  8  6  3  1  2  0  0   0
 [465,]  7  4  8  6  3  1  0  0  0   0
 [466,]  6  4  7  6  3  1  0  0  0   0
 [467,]  6  4  8  6  3  1  0  0  0   0
 [468,]  7  4  7  6  3  2  0  0  1   0
 [469,]  7  4  7  6  3  1  1  0  1   0
 [470,]  7  5  7  6  3  1  0  0  0   1
 [471,]  7  6  6  6  3  1  0  0  0   0
 [472,]  7  6  6  7  3  1  0  0  1   0
 [473,]  8  6  7  7  4  1  0  0  1   0
 [474,]  7  7  7  5  4  1  0  0  1   1
 [475,]  8  6  6  5  3  1  0  1  2   1
 [476,]  8  5  6  5  3  1  1  2  3   1
 [477,]  7  5  6  6  3  1  2  0  2   2
 [478,]  7  4  5  7  3  2  2  0  1   3
 [479,]  5  5  7  7  3  4  2  0  0   1
 [480,]  5  4  7  8  3  5  1  0  0   1
 [481,]  5  4  7  8  3  5  2  0  0   2
 [482,]  5  4  6  9  4  5  2  0  0   1
 [483,]  5  5  7  9  4  4  2  1  0   1
 [484,]  5  5  7 11  3  4  1  0  2   0
 [485,]  6  5  6  9  5  3  3  1  0   0
 [486,]  6  4  7  9  4  4  2  0  1   0
 [487,]  6  5  6  8  6  4  1  1  1   0
 [488,]  6  4  6  9  3  3  1  1  0   0
 [489,]  6  4  9  8  3  3  1  0  0   0
 [490,]  6  4 10  8  3  3  1  0  0   1
 [491,]  7  5  8  7  3  3  0  1  1   0
 [492,]  7  4  7  7  3  3  1  1  1   1
 [493,]  8  5  6  7  4  2  0  0  0   1
 [494,]  8  5  6  7  3  2  1  0  0   1
 [495,]  8  5  5  8  3  2  2  0  0   1
 [496,]  8  6  5  9  4  2  1  0  0   1
 [497,]  8  5  5  8  4  2  1  0  0   1
 [498,]  8  5  6  7  4  2  1  0  0   1
 [499,]  8  5  5  7  4  3  1  0  1   1
 [500,]  8  5  6  7  4  3  1  0  0   1
 [501,]  9  5  6  7  4  2  2  0  0   1
 [502,]  9  5  5  7  4  2  1  0  0   2
 [503,]  8  4  6  7  4  2  1  0  1   2
 [504,]  8  5  6  7  4  2  1  0  0   2
 [505,]  8  4  5  7  4  2  1  0  0   2
 [506,]  8  4  5  7  4  2  1  0  0   2
 [507,]  8  4  6  7  4  2  0  0  0   0
 [508,]  8  4  6  7  4  2  0  0  0   0
 [509,]  9  4  6  7  4  2  1  0  0   0
 [510,]  9  4  6  7  4  2  1  0  0   1
 [511,] 11  4  6  6  4  2  0  0  0   0
 [512,] 11  4  6  6  4  2  0  0  0   1
 [513,] 11  3  6  6  4  2  0  0  0   1
 [514,] 10  3  6  6  6  3  1  0  1   1
 [515,] 11  3  6  6  5  2  1  0  2   1
 [516,]  9  3  5  6  7  2  0  1  1   1
 [517,] 10  4  5  6  5  2  0  1  0   1
 [518,] 10  4  5  6  5  2  0  1  1   0
 [519,]  9  3  5  6  5  3  0  0  0   0
 [520,] 10  4  5  5  5  3  0  0  0   0
 [521,]  9  7  5  5  5  2  0  0  0   0
 [522,]  8  6  5  5  5  1  0  0  0   0
 [523,]  8  5  6  5  5  1  1  0  0   0
 [524,]  8  6  5  5  5  1  1  1  0   0
 [525,]  7  5  5  6  6  1  1  1  0   0
 [526,]  7  5  6  6  4  2  1  0  0   2
 [527,]  7  6  5  7  5  2  2  0  0   2
 [528,]  8  7  5  6  4  2  2  0  0   2
 [529,]  9  7  5  5  4  2  2  0  0   1
 [530,]  9  5  5  6  6  2  2  1  0   1
 [531,]  8  5  5  6  5  3  3  2  0   0
 [532,]  8  5  5  5  4  2  4  2  0   1
 [533,]  8  6  5  5  4  2  3  1  0   2
 [534,]  8  6  6  5  4  2  1  1  1   3
 [535,]  8  6  4  5  5  3  1  0  1   3
 [536,]  9  6  4  7  5  2  0  0  1   2
 [537,]  9  6  4  7  4  2  0  0  1   2
 [538,]  9  6  4  7  5  2  0  0  1   2
 [539,]  8  6  4  7  4  2  0  2  0   1
 [540,]  8  6  4  7  3  2  0  0  0   1
 [541,]  8  6  4  6  3  3  0  0  0   1
 [542,]  9  6  4  5  3  4  0  0  0   1
 [543,]  9  8  4  6  3  2  0  0  0   1
 [544,]  9  7  4  5  3  3  0  0  1   1
 [545,] 10  7  4  5  3  2  0  0  2   1
 [546,] 10  6  4  5  3  2  0  0  2   1
 [547,]  9  6  4  5  3  2  0  1  1   1
 [548,]  8  7  4  5  3  1  0  0  1   2
 [549,]  8  6  4  5  3  1  1  0  1   1
 [550,]  7  6  5  5  3  1  0  2  1   1
 [551,]  7  6  4  5  3  1  1  2  2   0
 [552,]  7  6  4  5  4  1  1  1  2   2
 [553,]  8  6  5  5  3  1  1  1  2   2
 [554,]  8  7  5  5  3  1  1  1  2   1
 [555,]  7  7  5  5  3  1  1  1  2   2
 [556,]  7  7  5  5  3  4  1  1  2   0
 [557,]  7  7  5  5  3  4  1  1  2   0
 [558,]  7  6  5  5  3  3  3  1  1   0
 [559,]  7  6  6  5  3  1  2  1  1   0
 [560,]  7  4  6  6  4  1  1  1  1   0
 [561,]  8  4  6  6  5  1  1  2  1   1
 [562,]  8  4  7  5  4  1  2  1  1   0
 [563,]  8  5  8  5  4  1  1  0  2   0
 [564,]  8  6  7  5  3  1  1  0  1   0
 [565,]  8  4  8  6  3  1  0  1  2   1
 [566,]  7  5  8  5  5  2  0  1  2   0
 [567,]  8  4  8  6  3  2  1  0  1   1
 [568,]  8  5  7  5  3  3  3  0  1   1
 [569,]  8  5  7  7  3  3  0  1  1   2
 [570,]  7  4  7  6  3  2  0  1  2   3
 [571,]  7  5  9  6  3  2  0  0  3   2
 [572,]  8  5  7  7  3  2  0  0  2   2
 [573,]  8  5  7  6  3  2  1  0  3   2
 [574,]  8  6  6  6  3  2  1  0  3   2
 [575,]  8  6  7  7  3  2  0  1  2   2
 [576,]  8  4  6  6  4  4  2  0  2   2
 [577,]  8  4  5  6  4  3  1  0  4   1
 [578,]  9  4  5  8  4  4  0  0  3   0
 [579,]  8  5  5  8  4  3  0  2  3   0
 [580,]  7  7  5  7  5  2  0  0  2   0
 [581,]  7  7  5  6  4  1  0  0  2   2
 [582,]  7  7  5  6  4  1  0  0  2   2
 [583,]  7  5  5  6  4  1  1  0  2   2
 [584,]  7  5  5  6  5  1  2  0  2   2
 [585,]  7  5  5  7  5  1  0  0  2   2
 [586,]  8  4  5  7  4  1  0  0  2   1
 [587,]  8  3  5  6  4  2  0  0  2   1
 [588,]  8  3  5  7  4  1  0  0  1   1
 [589,]  8  4  5  6  4  2  1  0  0   0
 [590,]  7  4  7  6  4  2  0  0  0   0
 [591,]  7  5  7  6  4  2  0  0  0   0
 [592,]  7  4  7  6  4  2  0  1  0   0
 [593,]  7  4  8  6  4  2  0  1  0   0
 [594,]  7  4  8  6  4  2  0  0  0   0
 [595,]  7  3  7  9  4  1  0  1  0   1
 [596,]  7  4  7  9  5  1  1  0  0   0
 [597,]  8  3  7  8  5  1  0  0  0   1
 [598,]  8  3  7  7  6  1  0  0  0   0
 [599,]  7  4  6  6  5  1  0  1  1   0
 [600,]  7  3  6  6  5  1  0  1  0   1
 [601,]  9  2  7  6  5  1  0  1  0   1
 [602,]  8  2  9  6  5  1  0  1  0   2
 [603,]  9  2  7  6  5  1  0  1  0   2
 [604,]  9  2  6  6  6  2  0  1  0   1
 [605,]  8  2  6  6  6  2  0  0  0   1
 [606,]  8  3  6  6  5  2  1  0  0   0
 [607,]  8  3  7  7  5  1  0  0  1   0
 [608,]  8  2  6  7  5  1  0  2  1   1
 [609,]  8  3  6  7  5  1  0  0  2   0
 [610,]  8  3  6  7  6  1  0  0  1   0
 [611,]  9  3  6  7  6  1  0  0  1   0
 [612,]  9  3  6  7  6  1  0  0  1   0
 [613,]  9  3  6  7  6  1  1  0  1   0
 [614,]  8  3  6  8  6  2  1  0  1   1
 [615,]  9  3  6  7  6  2  0  0  1   1
 [616,]  8  3  6  8  5  1  0  0  1   1
 [617,]  7  3  6  8  4  1  0  0  2   0
 [618,]  8  3  6  8  4  1  0  0  2   0
 [619,]  7  3  6  8  5  1  0  0  2   1
 [620,]  7  3  6  8  5  2  0  0  2   0
 [621,]  8  2  6  7  5  2  0  0  2   0
 [622,]  8  2  7  7  5  1  0  0  2   1
 [623,]  8  3  7  7  5  2  0  0  2   0
 [624,]  8  3  7  7  5  2  0  0  2   0
 [625,]  9  3  6  7  5  2  0  0  2   0
 [626,]  8  3  7  7  5  2  0  0  2   0
 [627,]  8  2  5  7  4  3  0  0  2   1
 [628,]  8  2  5  7  4  3  0  1  2   0
 [629,]  9  3  5  7  4  3  0  1  2   0
 [630,]  7  3  5  7  4  3  0  1  3   1
 [631,]  6  3  5  7  4  3  0  1  2   0
 [632,]  6  3  5  7  4  3  0  1  2   0
 [633,]  6  3  5  7  5  3  0  1  2   0
 [634,]  6  2  5  7  4  3  0  1  3   0
 [635,]  6  2  5  7  4  4  0  1  2   0
 [636,]  6  2  5  7  5  2  0  1  2   0
 [637,]  6  2  5  7  5  2  1  1  2   0
 [638,]  6  3  5  8  5  2  1  1  2   0
 [639,]  6  3  5  8  5  2  1  1  2   0
 [640,]  6  3  5  7  4  3  0  1  2   0
 [641,]  8  3  5  7  5  3  0  1  2   0
 [642,]  8  3  5  7  5  3  0  1  2   0
 [643,]  8  3  5  7  5  3  0  1  2   0
 [644,]  8  3  5  6  6  3  0  1  2   0
 [645,]  8  3  5  6  5  3  0  1  2   0
 [646,]  8  3  6  6  5  3  0  1  2   0
 [647,]  8  3  6  6  5  3  0  1  3   0
 [648,]  9  3  6  6  5  3  0  0  2   0
 [649,]  8  4  5  7  5  4  1  0  2   0
 [650,]  9  3  5  7  5  4  2  0  3   1
 [651,]  9  3  5  7  5  4  3  0  2   1
 [652,]  8  3  6  7  5  3  3  3  2   0
 [653,]  8  3  6  7  5  4  2  1  3   0
 [654,]  8  3  6  7  5  4  2  1  3   0
 [655,]  8  3  7  8  5  4  1  1  3   0
 [656,]  8  4  7  7  4  3  0  1  4   0
 [657,]  8  4  5  7  5  3  0  1  3   0
 [658,]  7  4  5  7  5  4  0  1  3   1
 [659,]  7  4  5  6  5  4  0  1  3   1
 [660,]  7  5  5  7  5  3  0  1  3   0
 [661,]  7  4  5  6  5  3  0  1  2   0
 [662,]  7  4  6  6  5  2  0  1  2   0
 [663,]  7  4  6  6  6  2  0  1  1   0
 [664,]  7  3  7  6  6  2  1  1  1   0
 [665,]  7  5  7  6  5  2  1  1  1   0
 [666,]  9  4  6  6  7  1  0  1  0   0
 [667,]  9  4  5  7  6  1  0  1  0   2
 [668,]  7  4  5  7  5  2  1  1  1   1
 [669,]  8  4  5  7  5  2  1  1  2   0
 [670,]  8  4  5  6  6  2  0  1  2   0
 [671,]  8  4  5  6  6  2  0  2  1   1
 [672,]  8  4  5  7  6  2  1  1  1   0
 [673,]  8  5  5  7  5  2  2  2  1   0
 [674,]  9  4  5  7  5  2  2  3  1   0
 [675,]  9  4  5  6  5  3  2  2  0   1
 [676,]  8  5  5  7  6  3  3  1  0   0
 [677,]  8  5  5  7  5  4  3  1  0   0
 [678,]  7  3  5  7  5  3  3  1  1   0
 [679,]  7  3  5  7  5  2  4  1  1   0
 [680,]  7  2  5  8  5  3  4  1  0   0
 [681,]  7  3  5  7  5  2  4  1  0   0
 [682,]  6  3  5  7  5  2  4  2  0   1
 [683,]  8  2  5  8  6  2  2  3  0   0
 [684,]  8  2  5  8  6  3  1  2  0   0
 [685,]  8  2  6  7  5  3  3  2  0   0
 [686,]  8  3  6  7  5  3  3  1  0   0
 [687,]  7  4  7  7  5  4  2  1  0   0
 [688,]  7  3  5  7  6  4  1  2  0   0
 [689,]  7  3  6  7  6  4  1  2  0   1
 [690,]  8  3  6  7  6  5  1  2  0   1
 [691,]  9  4  6  7  7  4  1  2  0   0
 [692,]  9  4  6  7  7  4  0  2  0   0
 [693,]  8  3  5  7  7  3  0  3  0   1
 [694,]  7  3  5  7  6  3  1  2  0   2
 [695,]  7  3  5  7  7  3  1  2  0   1
 [696,]  7  3  5  7  6  4  1  2  0   1
 [697,]  7  2  5  7  5  4  1  3  1   0
 [698,]  8  2  5  6  6  4  0  2  1   0
 [699,]  8  3  6  6  5  3  0  2  1   0
 [700,]  7  3  6  6  6  3  0  1  1   0
 [701,]  7  2  6  6  6  4  0  1  3   0
 [702,]  7  2  6  6  6  5  0  1  1   1
 [703,]  7  2  6  6  7  5  0  1  1   1
 [704,]  7  3  7  6  6  3  1  1  0   0
 [705,]  7  4  6  7  6  3  1  1  0   0
 [706,]  7  5  6  7  6  3  1  1  0   0
 [707,]  7  7  5  7  6  3  1  1  0   0
 [708,]  7  6  5  7  5  3  2  1  0   0
 [709,]  7  6  5  7  5  2  2  1  0   0
 [710,]  7  5  5  6  5  2  1  2  0   0
 [711,]  8  4  5  6  5  2  1  1  0   0
 [712,]  7  5  5  6  5  2  1  1  0   0
 [713,]  7  3  5  6  5  2  1  2  0   0
 [714,]  7  3  5  7  5  2  1  1  0   0
 [715,]  7  3  5  7  6  2  1  0  0   0
 [716,]  7  4  5  6  6  2  2  0  0   0
 [717,]  8  4  5  6  5  3  1  0  0   1
 [718,]  7  4  5  6  5  3  2  0  0   2
 [719,]  7  5  5  6  5  4  2  1  1   1
 [720,]  7  5  5  7  5  3  2  2  1   1
 [721,]  7  4  5  7  5  4  2  1  0   1
 [722,]  7  2  5  7  5  3  2  1  0   0
 [723,]  7  2  5  7  5  3  1  1  0   1
 [724,]  7  2  6  7  5  4  1  1  0   1
 [725,]  8  2  6  7  5  4  1  2  0   1
 [726,]  7  4  5  6  5  2  1  2  0   1
 [727,]  8  3  6  6  5  2  1  1  0   0
 [728,] 10  3  5  6  7  2  1  1  0   2
 [729,]  8  3  6  6  7  2  0  1  0   1
 [730,]  8  3  7  7  5  3  0  2  1   0
 [731,]  9  3  7  7  5  4  0  0  0   0
 [732,]  8  4  7  6  5  2  0  1  0   1
 [733,]  7  4  8  6  5  2  0  0  0   0
 [734,]  7  3  8  6  5  2  0  0  1   0
 [735,]  7  3  7  8  5  3  0  0  0   0
 [736,]  7  3  7  7  5  4  0  0  0   0
 [737,]  8  3  7  7  5  3  0  0  0   0
 [738,]  8  4  7  6  5  3  0  0  0   0
 [739,]  8  4  7  6  5  3  0  1  0   0
 [740,]  8  4  7  6  5  2  0  1  0   1
 [741,]  7  4  7  8  5  1  1  1  0   2
 [742,]  7  5  8  8  5  1  1  1  0   1
 [743,]  7  5  7  8  5  1  1  0  0   1
 [744,]  7  6  7  8  5  1  1  0  0   0
 [745,]  7  6  7  7  5  1  1  0  2   0
 [746,]  7  6  7  6  5  1  0  0  1   0
 [747,]  8  5  7  7  5  1  0  0  1   0
 [748,]  7  5  6  7  5  1  1  0  1   1
 [749,]  7  5  6  6  5  1  1  0  0   0
 [750,]  7  5  6  7  5  1  1  0  1   1
 [751,]  7  5  6  7  5  1  0  0  1   1
 [752,]  7  4  7  7  5  2  0  1  1   0
 [753,]  7  3  7  8  5  4  1  1  0   0
 [754,]  7  5  7  6  4  3  0  1  0   1
 [755,]  7  5  7  6  5  1  0  1  0   1
 [756,]  7  5  6  6  5  1  0  1  0   1
 [757,]  8  5  6  6  5  1  0  1  0   1
 [758,]  7  4  6  7  5  1  0  1  0   2
 [759,]  7  4  7  6  5  1  0  1  1   0
 [760,]  7  4  6  6  5  2  1  1  0   0
 [761,]  9  4  6  6  6  1  1  1  0   0
 [762,]  8  4  6  6  5  2  1  1  0   1
 [763,]  9  3  6  6  5  3  1  1  1   0
 [764,]  8  3  7  8  5  3  1  1  1   0
 [765,]  8  3  7  6  6  3  2  0  2   0
 [766,]  8  3  7  6  6  3  1  0  3   0
 [767,]  9  3  7  7  5  3  1  0  1   0
 [768,]  9  3  8  6  5  3  2  0  1   0
 [769,]  8  3  9  6  5  3  2  0  1   0
 [770,]  8  3  7  7  5  3  2  0  1   0
 [771,]  8  3  7  6  5  2  3  0  1   0
 [772,]  7  3  7  7  5  2  3  1  1   0
 [773,]  7  3  8  8  5  2  1  1  2   1
 [774,]  7  4  7  8  5  2  0  1  1   1
 [775,]  8  4  7  6  5  3  0  1  1   1
 [776,]  8  4  8  6  5  3  0  1  1   0
 [777,]  7  4  8  7  5  2  0  0  2   0
 [778,]  7  4  7  7  5  2  3  0  0   0
 [779,]  7  3  8  7  5  3  1  0  1   1
 [780,]  7  3  8  6  6  3  1  1  1   0
 [781,]  8  3  9  6  6  4  0  1  1   0
 [782,]  8  4 10  6  5  4  0  1  1   0
 [783,]  8  3 10  6  6  3  1  1  1   1
 [784,]  8  3 10  6  6  2  1  1  1   1
 [785,]  8  3  8  6  5  3  1  1  2   2
 [786,]  8  3  9  6  5  3  1  0  2   2
 [787,] 10  3  9  6  5  4  1  0  2   1
 [788,]  9  3 10  6  5  4  1  0  1   1
 [789,] 10  3  9  6  5  5  1  0  1   1
 [790,]  8  3  9  6  5  5  1  0  1   1
 [791,]  8  3  8  6  5  3  1  0  2   1
 [792,]  9  3  8  7  5  3  0  0  2   1
 [793,]  8  3  8  6  5  3  0  0  1   1
 [794,]  8  3  8  6  5  3  0  0  1   1
 [795,]  7  4  8  6  5  3  0  0  1   0
 [796,]  7  4  8  6  6  3  0  0  1   0
 [797,]  7  4  8  6  5  3  0  0  1   1
 [798,]  8  3  8  6  5  3  0  0  1   1
 [799,]  7  3  8  6  5  4  0  1  1   2
 [800,]  8  3  8  6  6  3  0  0  1   0
 [801,]  8  3  8  6  6  3  0  0  1   0
 [802,]  7  3  8  7  6  3  0  0  1   1
 [803,]  7  3  8  7  6  3  1  0  2   0
 [804,]  7  4  7  7  5  3  0  0  2   0
 [805,]  7  4  7  7  5  3  0  0  1   1
 [806,]  7  4  7  7  5  3  0  0  1   0
 [807,]  6  4  8  7  5  3  0  0  2   0
 [808,]  7  4  7  8  5  3  0  3  0   0
 [809,]  7  3  7  9  5  3  1  1  0   0
 [810,]  7  3  7  8  5  3  1  2  1   0
 [811,]  7  3  7  7  5  4  1  2  1   0
 [812,]  7  4  7  7  5  3  0  1  1   0
 [813,]  6  4  7  7  5  3  0  0  1   0
 [814,]  6  4  7  8  5  3  0  0  1   0
 [815,]  6  5  7  8  6  2  0  0  0   1
 [816,]  5  4  7  8  5  2  0  0  2   0
 [817,]  5  5  7  8  5  3  0  0  1   0
 [818,]  5  5  7  7  5  3  0  0  0   0
 [819,]  6  5  7  7  5  4  0  0  1   0
 [820,]  5  6  7  8  5  4  0  0  1   0
 [821,]  5  6  7  6  5  3  0  0  0   0
 [822,]  5  6  7  6  5  2  0  1  0   1
 [823,]  5  5  7  7  5  2  0  1  0   1
 [824,]  5  5  7  7  5  2  0  1  0   1
 [825,]  5  4  7  7  5  3  0  1  0   1
 [826,]  5  4  7  7  6  3  0  0  1   0
 [827,]  6  4  7  7  6  3  0  0  0   0
 [828,]  6  5  7  7  5  3  0  0  0   0
 [829,]  5  5  7  7  5  3  0  0  0   0
 [830,]  6  4  7  7  5  3  0  0  0   0
 [831,]  6  4  7  8  6  3  0  0  0   0
 [832,]  6  5  7  7  6  3  0  0  0   0
 [833,]  6  5  7  7  6  2  0  1  1   0
 [834,]  6  5  7  7  5  4  1  1  1   0
 [835,]  6  5  8  7  5  3  0  1  1   0
 [836,]  6  5  8  7  6  2  0  0  1   0
 [837,]  6  8  9  7  6  1  0  0  0   0
 [838,]  8  8  7  7  6  1  0  0  0   0
 [839,]  7  8  7  6  6  2  0  0  0   1
 [840,]  7  7  7  6  7  1  0  0  0   1
 [841,]  7  5  7  6  6  1  0  0  0   0
 [842,]  7  5  7  7  5  1  0  0  0   0
 [843,]  7  5  7  7  6  1  1  0  0   0
 [844,]  7  5  7  6  5  2  0  0  0   0
 [845,]  8  5  7  6  5  2  0  0  0   0
 [846,]  7  5  7  6  5  2  0  0  0   0
 [847,]  6  5  7  6  5  2  0  0  0   0
 [848,]  6  5  7  6  5  1  0  0  0   0
 [849,]  6  5  7  6  6  1  0  1  1   0
 [850,]  6  5  7  6  5  1  0  1  0   0
 [851,]  6  4  7  7  5  1  0  0  0   0
 [852,]  6  4  7  8  5  1  0  1  0   0
 [853,]  6  4  6  8  5  1  0  0  1   0
 [854,]  7  4  6  7  5  2  0  0  0   1
 [855,]  6  4  6  7  5  3  0  0  0   3
 [856,]  6  5  8  7  5  1  0  0  0   2
 [857,]  6  4  8  7  5  1  0  0  0   2
 [858,]  6  4  7  7  5  1  1  0  1   2
 [859,]  8  4  7  7  5  1  0  0  0   2
 [860,]  6  4  6  8  5  1  0  0  2   3
 [861,]  7  5  6  6  6  1  0  0  2   3
 [862,]  6  4  6  7  7  2  0  0  1   2
 [863,]  7  4  6  7  7  1  0  0  1   1
 [864,]  7  4  6  6  6  2  1  0  0   0
 [865,]  7  4  6  6  6  2  0  0  1   1
 [866,]  8  4  6  7  6  2  0  0  0   0
 [867,]  8  4  6  7  6  1  0  0  0   0
 [868,]  7  4  6  7  6  1  0  1  0   0
 [869,]  7  4  6  6  7  1  0  0  0   1
 [870,]  7  4  6  6  7  1  0  0  0   1
 [871,]  7  5  6  6  6  1  0  0  0   0
 [872,]  7  4  6  6  6  1  1  1  0   1
 [873,]  6  5  7  6  6  1  0  1  0   0
 [874,]  8  4  7  6  6  1  2  0  0   0
 [875,]  7  4  7  6  6  1  2  0  1   0
 [876,]  7  4  8  6  6  1  1  0  0   1
 [877,]  7  4  8  6  5  2  1  0  1   0
 [878,]  7  4  8  6  5  2  1  1  1   0
 [879,]  7  4  7  6  6  2  1  1  0   0
 [880,]  7  4  6  6  6  2  1  1  1   0
 [881,]  7  4  6  6  6  2  1  1  2   0
 [882,]  7  4  7  6  6  3  0  1  2   0
 [883,]  7  4  7  6  6  2  0  1  2   0
 [884,]  7  4  7  6  6  2  0  1  1   0
 [885,]  7  4  7  7  5  2  0  1  2   0
 [886,]  7  5  7  7  5  2  0  1  1   0
 [887,]  7  4  7  6  5  2  0  1  1   0
 [888,]  8  4  7  6  5  2  0  1  1   0
 [889,]  8  4  7  7  5  2  1  1  1   0
 [890,]  8  4  6  7  6  2  1  1  1   0
 [891,]  8  4  7  7  5  2  1  1  1   0
 [892,]  8  5  6  6  5  2  1  1  1   0
 [893,]  8  5  6  7  5  2  0  2  1   0
 [894,]  8  5  6  6  5  2  0  1  1   0
 [895,]  9  5  7  6  5  2  0  1  1   0
 [896,]  8  4  7  6  5  2  1  1  1   0
 [897,]  7  4  6  6  5  2  0  2  1   0
 [898,]  7  4  8  6  5  2  0  2  1   0
 [899,]  7  4  6  6  5  2  0  2  1   1
 [900,]  7  4  5  6  7  2  0  2  1   0
 [901,]  7  4  6  6  5  2  1  1  2   1
 [902,]  8  4  6  6  5  2  1  1  0   1
 [903,]  8  4  7  7  5  2  0  1  0   1
 [904,]  7  4  6  8  5  2  1  1  0   0
 [905,]  7  4  6  6  5  3  1  0  0   0
 [906,]  8  4  6  8  5  3  0  0  0   0
 [907,]  8  4  6  8  5  3  0  1  0   0
 [908,]  8  4  6  8  4  3  0  1  0   0
 [909,]  8  5  6  8  4  3  1  0  1   0
 [910,]  7  6  6  7  4  3  0  0  2   0
 [911,]  8  4  7  6  4  4  1  0  1   0
 [912,]  8  4  6  6  4  4  1  0  1   0
 [913,]  8  4  6  6  5  3  2  0  1   1
 [914,]  8  5  6  5  4  3  0  1  2   1
 [915,]  8  6  6  5  4  2  0  2  1   2
 [916,]  9  6  7  6  4  2  1  0  1   1
 [917,]  8  6  7  6  5  2  1  0  1   4
 [918,]  8  5  7  6  4  4  1  0  1   0
 [919,]  8  4  7  5  4  4  1  2  1   1
 [920,]  8  4  7  5  4  4  2  1  2   0
 [921,]  8  4  7  5  5  3  2  0  1   0
 [922,]  8  4  8  6  5  3  2  0  1   0
 [923,]  9  4  8  6  4  3  2  0  1   0
 [924,]  8  4  9  6  4  3  2  0  1   1
 [925,]  8  4  9  6  4  2  2  1  1   2
 [926,]  7  4  9  6  4  2  1  1  1   2
 [927,]  7  5 10  6  4  2  2  0  1   1
 [928,]  7  4  9  6  5  3  2  0  1   1
 [929,]  7  4  9  6  5  4  1  1  1   1
 [930,]  7  5  9  7  5  4  1  0  1   0
 [931,]  7  6  9  7  6  3  1  1  1   0
 [932,]  7  6  8  8  6  3  1  0  1   1
 [933,]  7  5  8  8  7  3  1  0  1   0
 [934,]  7  4  8  9  7  3  1  0  1   0
 [935,]  7  4  8  8  6  3  1  1  1   0
 [936,]  8  4  9  8  6  3  1  1  1   0
 [937,]  8  4  8  7  6  3  1  1  1   0
 [938,]  8  4  9  7  5  3  1  0  1   0
 [939,]  7  4  8  8  5  4  0  0  1   0
 [940,]  7  5  9  8  5  5  0  0  1   0
 [941,]  7  4  9  6  7  5  1  0  1   0
 [942,]  6  4  8  6  6  6  2  0  1   0
 [943,]  6  7  7  6  6  6  1  0  2   0
 [944,]  7  7  7  6  6  6  0  0  1   0
 [945,]  8  5  7  6  6  5  1  0  2   0
 [946,]  8  5  8  6  5  4  0  0  2   0
 [947,]  8  4  8  6  5  4  1  0  2   0
 [948,]  8  6  8  6  4  4  1  0  2   0
 [949,]  8  5  7  6  4  5  1  1  2   0
 [950,]  8  4  7  6  4  3  1  1  2   0
 [951,]  8  4  7  6  4  4  0  1  2   0
 [952,]  8  4  7  6  4  4  0  1  2   0
 [953,]  7  4  7  6  4  5  0  1  2   0
 [954,]  7  4  7  6  4  4  0  1  2   0
 [955,]  9  4  7  6  4  4  0  1  2   0
 [956,]  9  4  7  6  4  4  0  1  3   0
 [957,]  9  5  7  6  4  3  1  1  2   0
 [958,]  9  5  7  7  4  3  1  1  2   0
 [959,]  8  5  7  7  4  4  1  1  2   0
 [960,]  8  5  8  7  4  4  0  1  2   0
 [961,] 10  5  8  8  4  2  0  1  3   0
 [962,]  9  4  9  8  4  2  1  1  3   0
 [963,]  9  4 10  7  4  2  0  1  2   0
 [964,] 10  4  7  7  4  2  0  0  2   0
 [965,]  9  4  6  7  4  4  0  0  1   1
 [966,] 10  5  6  7  4  3  0  1  1   1
 [967,]  9  6  7  8  4  2  0  0  1   1
 [968,] 10  6  7  8  4  2  0  0  1   0
 [969,]  8  6  7  7  4  2  1  2  1   0
 [970,]  8  6  7  7  4  2  0  0  2   0
 [971,]  8  7  7  6  4  3  0  0  2   0
 [972,]  7  5  8  7  4  3  0  0  2   0
 [973,]  7  6  8  6  5  2  0  0  3   0
 [974,]  7  5  8  6  4  2  0  0  3   1
 [975,]  7  6  8  6  4  2  0  1  1   1
 [976,]  6  5  8  7  4  2  1  1  0   2
 [977,]  6  6  8  7  4  3  0  0  0   3
 [978,]  6  5  9  7  4  3  1  0  0   3
 [979,]  7  4 10  6  5  3  1  0  0   3
 [980,]  6  6 10  6  4  3  1  1  2   1
 [981,]  7  6  9  6  4  3  0  1  0   1
 [982,]  7  4  7  6  4  3  0  1  1   1
 [983,]  6  4  8  6  4  3  0  2  1   2
 [984,]  7  4  6  7  4  4  0  1  1   1
 [985,]  7  4  7  6  6  3  0  0  3   0
 [986,]  7  5  7  7  5  4  0  1  2   0
 [987,]  7  4  7  7  5  4  0  1  2   0
 [988,]  7  5  7  7  5  4  1  0  1   0
 [989,]  7  5  8  7  5  3  1  0  1   1
 [990,]  7  5  8  7  5  3  0  0  1   2
 [991,]  7  4  8  6  5  3  0  1  1   2
 [992,]  7  4  9  5  4  3  0  0  1   2
 [993,]  6  4  8  5  5  3  1  0  1   1
 [994,]  6  4 10  5  5  3  0  0  0   1
 [995,]  6  4  8  5  5  3  0  1  0   1
 [996,]  7  4  8  5  5  4  0  2  0   0
 [997,]  7  5  8  5  5  3  0  0  2   2
 [998,]  8  5  8  6  5  4  0  0  1   2
 [999,]  8  5  7  5  5  4  0  0  1   2
[1000,]  8  4  8  5  5  4  0  0  0   2
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("get_var_props_over_chain")
> ### * get_var_props_over_chain
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: get_var_props_over_chain
> ### Title: Get the Variable Inclusion Proportions
> ### Aliases: get_var_props_over_chain
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 10
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y, num_trees = 20)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/20 iter 100/1250  mem: 43.3/1398.3MB
Sampling M_1/20 iter 200/1250  mem: 81.2/1398.3MB
Sampling M_1/20 iter 300/1250  mem: 109.6/1398.3MB
Sampling M_1/20 iter 400/1250  mem: 147.5/1398.3MB
Sampling M_1/20 iter 500/1250  mem: 175.9/1398.3MB
Sampling M_1/20 iter 600/1250  mem: 213.8/1398.3MB
Sampling M_1/20 iter 700/1250  mem: 242.2/1398.3MB
Sampling M_1/20 iter 800/1250  mem: 280.1/1398.3MB
Sampling M_1/20 iter 900/1250  mem: 308.5/1398.3MB
Sampling M_1/20 iter 1000/1250  mem: 346.4/1398.3MB
Sampling M_1/20 iter 1100/1250  mem: 374.8/1398.3MB
Sampling M_1/20 iter 1200/1250  mem: 403.2/1398.3MB
done building BART in 0.185 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #Get variable inclusion proportions
> var_props = get_var_props_over_chain(bart_machine)
> print(var_props)
        X1         X2         X3         X4         X5         X6         X7 
0.20505000 0.22408209 0.16334492 0.17199801 0.10329338 0.03364305 0.03409225 
        X8         X9        X10 
0.03577086 0.01529659 0.01342885 
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("init_java_for_bart_machine_with_mem_in_mb")
> ### * init_java_for_bart_machine_with_mem_in_mb
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: init_java_for_bart_machine_with_mem_in_mb
> ### Title: Initialize a JVM with a pre-specified heap size
> ### Aliases: init_java_for_bart_machine_with_mem_in_mb
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ##initialize a Java Virtual Machine with heap size of 3000MB
> ##this should be run before any BART models are built 
> ##init_java_for_bart_machine_with_mem_in_mb(3000) ##not run
> 
> 
> 
> cleanEx()
> nameEx("interaction_investigator")
> ### * interaction_investigator
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: interaction_investigator
> ### Title: Explore Pairwise Interactions in BART Model
> ### Aliases: interaction_investigator
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 10
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y, num_trees = 20)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/20 iter 100/1250  mem: 40.8/1398.3MB
Sampling M_1/20 iter 200/1250  mem: 78.7/1398.3MB
Sampling M_1/20 iter 300/1250  mem: 107.1/1398.3MB
Sampling M_1/20 iter 400/1250  mem: 145/1398.3MB
Sampling M_1/20 iter 500/1250  mem: 173.4/1398.3MB
Sampling M_1/20 iter 600/1250  mem: 201.8/1398.3MB
Sampling M_1/20 iter 700/1250  mem: 239.7/1398.3MB
Sampling M_1/20 iter 800/1250  mem: 268.1/1398.3MB
Sampling M_1/20 iter 900/1250  mem: 306/1398.3MB
Sampling M_1/20 iter 1000/1250  mem: 334.4/1398.3MB
Sampling M_1/20 iter 1100/1250  mem: 372.3/1398.3MB
Sampling M_1/20 iter 1200/1250  mem: 400.7/1398.3MB
done building BART in 0.164 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #investigate interactions
> interaction_investigator(bart_machine)
....
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("investigate_var_importance")
> ### * investigate_var_importance
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: investigate_var_importance
> ### Title: Explore Variable Inclusion Proportions in BART Model
> ### Aliases: investigate_var_importance
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 10
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y, num_trees = 20)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/20 iter 100/1250  mem: 39.3/1398.3MB
Sampling M_1/20 iter 200/1250  mem: 72.4/1398.3MB
Sampling M_1/20 iter 300/1250  mem: 105.5/1398.3MB
Sampling M_1/20 iter 400/1250  mem: 133.8/1398.3MB
Sampling M_1/20 iter 500/1250  mem: 166.9/1398.3MB
Sampling M_1/20 iter 600/1250  mem: 200/1398.3MB
Sampling M_1/20 iter 700/1250  mem: 233/1398.3MB
Sampling M_1/20 iter 800/1250  mem: 266.1/1398.3MB
Sampling M_1/20 iter 900/1250  mem: 299.2/1398.3MB
Sampling M_1/20 iter 1000/1250  mem: 332.3/1398.3MB
Sampling M_1/20 iter 1100/1250  mem: 360.6/1398.3MB
Sampling M_1/20 iter 1200/1250  mem: 393.7/1398.3MB
done building BART in 0.162 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #investigate variable inclusion proportions
> investigate_var_importance(bart_machine)
.....
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("k_fold_cv")
> ### * k_fold_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: k_fold_cv
> ### Title: Estimate Out-of-sample Error with K-fold Cross validation
> ### Aliases: k_fold_cv
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> #evaluate default BART on 5 folds
> k_fold_val = k_fold_cv(X, y)
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 73.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 206/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 272.2/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 338.3/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 470.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 83.6/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 147.3/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 218.2/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 282/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 345.8/1398.3MB
done building BART in 0.379 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 74.1/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 140.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 206.3/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 277.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 338.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 404.5/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 474.6/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 84.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 155/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 218.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 289.5/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 353.2/1398.3MB
done building BART in 0.366 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 73.9/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 139.6/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 205.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 270.8/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 336.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 406.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 471.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 90.5/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 153.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 217.1/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 287.4/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 350.7/1398.3MB
done building BART in 0.389 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 73.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 143.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 208.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 273.8/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 339.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 409.2/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 27/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 90/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 160/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 223/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 293/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 356/1398.3MB
done building BART in 0.368 sec 

burning and aggregating chains from all threads... done
.Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 73.3/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 143.2/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 208.4/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 273.6/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 343.4/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 408.6/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 26.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 96.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 159.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 229.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 292.3/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 362.1/1398.3MB
done building BART in 0.404 sec 

burning and aggregating chains from all threads... done

> print(k_fold_val$rmse)
[1] 1.545061
> 
> 
> 
> cleanEx()
> nameEx("pd_plot")
> ### * pd_plot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: pd_plot
> ### Title: Partial Dependence Plot
> ### Aliases: pd_plot
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 87.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 171.1/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 250.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 333.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 412.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 44.9/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 128.5/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 205.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 288.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 365.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 442.1/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 83/1398.3MB
done building BART in 0.444 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #partial dependence plot for quadratic term
> pd_plot(bart_machine, "X3")
...........
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> #Classification example
> 
> #get data and only use 2 factors
> data(iris)
> iris2 = iris[51:150,]
> iris2$Species = factor(iris2$Species)
> 
> #build BART classification model
> bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 51.5/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 97.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 143.3/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 189.3/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 235.2/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 281.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 327.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 373/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 418.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 30.1/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 78/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 125.9/1398.3MB
done building BART in 0.32 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #partial dependence plot 
> pd_plot(bart_machine, "Petal.Width")
...........
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("plot_convergence_diagnostics")
> ### * plot_convergence_diagnostics
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot_convergence_diagnostics
> ### Title: Plot Convergence Diagnostics
> ### Aliases: plot_convergence_diagnostics
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 87.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 169.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 247.5/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 329.6/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 411.7/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 48.8/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 131.1/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 206.6/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 288.9/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 371.2/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 446.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 94.6/1398.3MB
done building BART in 0.437 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #plot convergence diagnostics
> plot_convergence_diagnostics(bart_machine)
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("plot_y_vs_yhat")
> ### * plot_y_vs_yhat
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot_y_vs_yhat
> ### Title: Plot the fitted Versus Actual Response
> ### Aliases: plot_y_vs_yhat
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate linear data
> set.seed(11)
> n  = 500 
> p = 3
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 3*X[ ,1] + 2*X[ ,2] +X[ ,3] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 193.8/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 386.1/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 116.3/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 308.6/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 40/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 233/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 416.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 147.9/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 340.8/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 72.3/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 258.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 444.9/1398.3MB
done building BART in 0.813 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##generate plot
> plot_y_vs_yhat(bart_machine)
> 
> #generate plot with prediction bands
> plot_y_vs_yhat(bart_machine, prediction_intervals = TRUE)
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("predict")
> ### * predict
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.bartMachine
> ### Title: Make a prediction on data using a BART object
> ### Aliases: predict.bartMachine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 86/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.8/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 246.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 331.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 406.5/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 34/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 109.4/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 194.3/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 269.7/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 354.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 430/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 61.8/1398.3MB
done building BART in 0.414 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##make predictions on the training data
> y_hat = predict(bart_machine, X)
> 
> ##destroy BART model
> destroy_bart_machine(bart_machine)
> 
> #Classification example
> data(iris)
> iris2 = iris[51 : 150, ] #do not include the third type of flower for this example
> iris2$Species = factor(iris2$Species)  
> bart_machine = build_bart_machine(iris2[ ,1:4], iris2$Species)
Building BART for classification ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 60.6/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 107.5/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 145.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 192.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 239.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 286.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 333/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 380/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 427/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 473.7/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 73.6/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 120.2/1398.3MB
done building BART in 0.354 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##make probability predictions on the training data
> p_hat = predict(bart_machine, X)
Warning in colnames(new_data) == training_data_features :
  longer object length is not a multiple of shorter object length
[1] "colnames(new_data)"
[1] "X1" "X2" "X3" "X4" "X5"
[1] "training_data_features"
[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width" 
Warning: Are you sure you have the same feature names in the new record(s) as the training data?
> 
> ##make class predictions on test data
> y_hat_class = predict(bart_machine, X, type = "class")
Warning in colnames(new_data) == training_data_features :
  longer object length is not a multiple of shorter object length
[1] "colnames(new_data)"
[1] "X1" "X2" "X3" "X4" "X5"
[1] "training_data_features"
[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width" 
Warning: Are you sure you have the same feature names in the new record(s) as the training data?
> 
> ##make class predictions on test data conservatively for ''versicolor''
> y_hat_class_conservative = predict(bart_machine, X, type = "class", prob_rule_class = 0.9)
Warning in colnames(new_data) == training_data_features :
  longer object length is not a multiple of shorter object length
[1] "colnames(new_data)"
[1] "X1" "X2" "X3" "X4" "X5"
[1] "training_data_features"
[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width" 
Warning: Are you sure you have the same feature names in the new record(s) as the training data?
> 
> ##destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> 
> cleanEx()
> nameEx("print")
> ### * print
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: print.bartMachine
> ### Title: Summarizes information about a 'bartMachine' object.
> ### Aliases: print.bartMachine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 91.2/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.4/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 249.6/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 328.7/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 407.9/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 37.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 113.9/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 197.8/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 274.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 351.4/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 435.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 67/1398.3MB
done building BART in 0.393 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##print out details
> print(bart_machine)
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.5 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.59737 

in-sample statistics:
 L1 = 94.68 
 L2 = 87.33 
 rmse = 0.66 
 Pseudo-Rsq = 0.9813
p-val for shapiro-wilk test of normality of residuals: 0 
p-val for zero-mean noise: 0.24596 

> 
> ##Also, the default print works too
> bart_machine
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.5 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.59737 

in-sample statistics:
 L1 = 94.68 
 L2 = 87.33 
 rmse = 0.66 
 Pseudo-Rsq = 0.9813
p-val for shapiro-wilk test of normality of residuals: 0 
p-val for zero-mean noise: 0.24596 

> 
> ##destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("rmse_by_num_trees")
> ### * rmse_by_num_trees
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: rmse_by_num_trees
> ### Title: Assess the Out-of-sample RMSE by Number of Trees
> ### Aliases: rmse_by_num_trees
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 10
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y, num_trees = 20)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/20 iter 100/1250  mem: 41.7/1398.3MB
Sampling M_1/20 iter 200/1250  mem: 78.8/1398.3MB
Sampling M_1/20 iter 300/1250  mem: 106.7/1398.3MB
Sampling M_1/20 iter 400/1250  mem: 143.8/1398.3MB
Sampling M_1/20 iter 500/1250  mem: 171.7/1398.3MB
Sampling M_1/20 iter 600/1250  mem: 208.8/1398.3MB
Sampling M_1/20 iter 700/1250  mem: 236.6/1398.3MB
Sampling M_1/20 iter 800/1250  mem: 273.7/1398.3MB
Sampling M_1/20 iter 900/1250  mem: 301.6/1398.3MB
Sampling M_1/20 iter 1000/1250  mem: 338.7/1398.3MB
Sampling M_1/20 iter 1100/1250  mem: 366.6/1398.3MB
Sampling M_1/20 iter 1200/1250  mem: 403.7/1398.3MB
done building BART in 0.151 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #explore RMSE by number of trees
> rmse_by_num_trees(bart_machine)
num_trees = ..5..5..5..5..10..10..10..10..20..20..20..20..30..30..30..30..40..40..40..40..50..50..50..50..100..100..100..100..150..150..150..150..200..200..200..200
> 
> #destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("set_bart_machine_num_cores")
> ### * set_bart_machine_num_cores
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: set_bart_machine_num_cores
> ### Title: Set the Number of Cores for BART
> ### Aliases: set_bart_machine_num_cores
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> ## set all parallelized functions to use 4 cores
> ## set_bart_machine_num_cores(4) ##not run
> 
> 
> 
> cleanEx()
> nameEx("summary")
> ### * summary
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summary.bartMachine
> ### Title: Summarizes information about a 'bartMachine' object.
> ### Aliases: summary.bartMachine
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #Regression example
> 
> #generate Friedman data
> set.seed(11)
> n  = 200 
> p = 5
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 91.4/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 170.3/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 249.2/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 328.1/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 407/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 60.1/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 147.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 226.7/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 305.6/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 384.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 43.2/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 122.6/1398.3MB
done building BART in 0.364 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> ##print out details
> summary(bart_machine)
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.4 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.69538 

in-sample statistics:
 L1 = 88.27 
 L2 = 66.62 
 rmse = 0.58 
 Pseudo-Rsq = 0.9857
p-val for shapiro-wilk test of normality of residuals: 0.01842 
p-val for zero-mean noise: 0.26501 

> 
> ##Also, the default print works too
> bart_machine
Bart Machine v1.0b for regression

training data n = 200 and p = 5 
built in 0.4 secs on 1 core, 50 trees, 250 burn in and 1000 posterior samples

sigsq est for y beforehand: 7.281 
avg sigsq estimate after burn-in: 0.69538 

in-sample statistics:
 L1 = 88.27 
 L2 = 66.62 
 rmse = 0.58 
 Pseudo-Rsq = 0.9857
p-val for shapiro-wilk test of normality of residuals: 0.01842 
p-val for zero-mean noise: 0.26501 

> 
> ##destroy BART model
> destroy_bart_machine(bart_machine)
> 
> 
> 
> cleanEx()
> nameEx("var_selection_by_permute_response_cv")
> ### * var_selection_by_permute_response_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: var_selection_by_permute_response_cv
> ### Title: Perform Variable Selection Using Cross-validation Procedure
> ### Aliases: var_selection_by_permute_response_cv
> ### Keywords: ~kwd1 ~kwd2
> 
> ### ** Examples
> 
> #generate Friedman data
> set.seed(11)
> n  = 150 
> p = 100 ##95 useless predictors 
> X = data.frame(matrix(runif(n * p), ncol = p))
> y = 10 * sin(pi* X[ ,1] * X[,2]) +20 * (X[,3] -.5)^2 + 10 * X[ ,4] + 5 * X[,5] + rnorm(n)
> 
> ##build BART regression model (not actually used in variable selection)
> bart_machine = build_bart_machine(X, y)
Building BART for regression ...
building BART with mem-cache speedup
Sampling M_1/50 iter 100/1250  mem: 103.7/1398.3MB
Sampling M_1/50 iter 200/1250  mem: 191.9/1398.3MB
Sampling M_1/50 iter 300/1250  mem: 280.1/1398.3MB
Sampling M_1/50 iter 400/1250  mem: 368.3/1398.3MB
Sampling M_1/50 iter 500/1250  mem: 60.1/1398.3MB
Sampling M_1/50 iter 600/1250  mem: 145.4/1398.3MB
Sampling M_1/50 iter 700/1250  mem: 230.8/1398.3MB
Sampling M_1/50 iter 800/1250  mem: 316.2/1398.3MB
Sampling M_1/50 iter 900/1250  mem: 401.5/1398.3MB
Sampling M_1/50 iter 1000/1250  mem: 122.5/1398.3MB
Sampling M_1/50 iter 1100/1250  mem: 207.9/1398.3MB
Sampling M_1/50 iter 1200/1250  mem: 284.7/1398.3MB
done building BART in 0.412 sec 

burning and aggregating chains from all threads... done
evaluating in sample data...done
> 
> #variable selection via cross-validation
> var_sel_cv = var_selection_by_permute_response_cv(bart_machine, k_folds = 3)
cv #1
avg.....null...........................................................