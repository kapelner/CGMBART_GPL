\include{preamble}

\title{Some notes on the Metropolis-Hastings Implementation}

\date{}

\begin{document}
\maketitle

\section*{MCMC for BART}

According to Gelman p.291, the Metropolis-Hastings algorithm differs from the Metropolis algorithm because you need to consider the ratio of ratios:

\beqn
r = \frac{\dfrac{\cprob{\theta^*}{Y}}{J_t(\theta^* ~|~ \theta^{t-1})}}{\dfrac{\cprob{\theta^{t-1}}{Y}}{J_t(\theta^{t-1} ~|~ \theta^*)}} = \frac{J_t(\theta^{t-1} ~|~ \theta^*)}{J_t(\theta^* ~|~ \theta^{t-1})}\frac{\prob{\theta^* ~|~ Y}}{\prob{\theta^{t-1} ~|~ Y}}
\eeqn

Where we accept if a random draw from a uniform is less than the ratio above \ie $X \sim \uniform{0}{1} \leadsto x < r$. \\

The parameters of interest in our case are the new tree (which is created from one of three types of proposals), which we denote $T^*$, and the original tree, denoted by $T$. For jump notation which is $J$, we denote this just using the regular probability symbol (to be boring). We denote the residual left over from $Y$, the vector of random variables, as $\R := \bracks{\Roneton}^\top$. We denote $\sigsq$ as the random variable estimating the homoskedastic noise in the model which is sampled after all the trees are sampled. We do not notate all the hyperparameters to avoid notational messiness. The M-H ratio then becomes:

\beqn
r = \frac{\prob{T^* \rightarrow T}}{\prob{T \rightarrow T^*}} \frac{\cprob{T^*}{\R, \sigsq}}{\cprob{T}{\R, \sigsq}}
\eeqn

%We then use Bayes Rule to obtain the following which I partition form. We partition the ratio into three interpretable terms:

%\beqn
%r = \underbrace{\frac{\cprob{T}{T^*}}{\cprob{T^*}{T}}}_{\text{transitioning ratio}} \times \overbrace{\frac{\cprob{R}{T^*, \sigsq}}{\cprob{R}{T, \sigsq}}}^{\text{likelihood ratio}} \times \underbrace{\frac{\prob{T^*}}{\prob{T}}}_{\text{tree structure ratio}}
%\eeqn

My goal is to come up with an exact way of calculating $r$ for all possible tree proposals.\\

Throughout this document, we use the following notation:

\begin{itemize}
\item $\Hint$ ---  the collection of internal nodes in tree $T$
\item $\Hleaves$ ---  the collection of leaves in tree $T$
\item $\eta$ --- a node $\in \Hint \cup \Hleaves$.
\item $d_\eta$ --- the depth of the $\eta$th node. The root node is defined as having depth 0, its first child has depth 1, etc.
\item $b$ --- the number of terminal nodes / leaves in the tree $T$, $\abss{\Hleaves}$. These are the nodes that can potentially be ``grown.'' For example, the number of terminal nodes in the $T^*$ tree is $b+1$ if $T$ was grown and $b-1$ if $T$ was pruned.
\item $w_2$ --- the number of 2nd generation internal nodes in tree $T$, $\abss{\Hint}$ \ie the number of nodes who only have two children. These are the nodes that can potentially be ``pruned.''
\item $w_2^*$ --- the number of 2nd generation internal nodes in tree $T^*$, $\abss{\Hint^*}$. This can be equal to $w$ or $w+1$ so it has to be recalculated. Draw a few pictures of trees and grow steps and you'll see why this unfortunate fact is so.
%\item $w$ --- the number of internal nodes regardless of generation (even the root is included in this count).
\item  $\ell$ --- the index of the terminal node which we've ``picked'' to grow from it is a number $\in \braces{1, \ldots, b}$.
\item $\ell_L$ and $\ell_R$ --- represent the new left and right node indices in tree $T^*$ which are ``grown'' from the $\ell$th node of tree $T$
\end{itemize}

\subsection*{Likelihood Calculation}

It is imperative that we can calculate $\cprob{T}{\R, \sigsq}$ for the calculation of $r$. Let's analyze carefully what it means to get the likelihood of a tree.

First, note that the likelihood for $T$ given the data is not defined in our model, so we use Bayes Rule to obtain something that is tractable in our model:

\beqn
\cprob{T}{\R, \sigsq} = \frac{\cprob{\R}{T, \sigsq} \cprob{T}{\sigsq}}{\cprob{\R}{\sigsq}}
\eeqn

What's in the numerator? The likelihood of the data given the tree and the variance times the probability of the tree given the variance. The probability of the tree is based on probabilities of splits and rules and is not dependent on the variance, $\cprob{T}{\sigsq} = \prob{T}$, so we can already simplify to:

\beqn
\cprob{T}{\R, \sigsq} = \frac{\cprob{\R}{T, \sigsq} \prob{T}}{\cprob{\R}{\sigsq}}
\eeqn

What about the denominator --- the probability of the data? The probability of the data is weighted over every possible tree configuration:

\beqn
\cprob{\R}{\sigsq} = \int_{T \in \mathcal{T}} \cprob{\R}{T, \sigsq} \prob{T} dT
\eeqn

and removing the dependency on $T$ becomes:

\beqn
\cprob{\R}{\sigsq} = \int_{T \in \mathcal{T}} \prod_{\ell=1}^{b_T} \cprob{\Rlonetonl}{\sigsq} \prob{T} dT
\eeqn

which of course is arrived at via the margining out of the means of each leaf:

\beqn
\cprob{\R}{\sigsq} = \int_{T \in \mathcal{T}} \parens{\prod_{\ell=1}^{b_T} \int_\reals \cprob{\Rlonetonl}{\mu, \sigsq} \prob{\mu; \sigsq_\mu} d\mu} \prob{T} dT
\eeqn

The point being is that this quantity is the same for all data $\R$. This is useful since we're creating ratios where we're using the same data, and this quantity will cancel.

Now let's look at the ratio of the likelihoods which is what we care about for the calculation of $r$. I identify three pieces which we will use for the next couple of sections:

\beqn
r &=& \frac{\prob{T^* \rightarrow T}}{\prob{T \rightarrow T^*}} \underbrace{\frac{\cprob{T^*}{\R, \sigsq}}{\cprob{T}{\R, \sigsq}}} \\
&& \quad\quad\quad\quad~~ \frac{\dfrac{\cprob{\R}{T^*, \sigsq} \prob{T^*}}{\cancel{\cprob{\R}{\sigsq}}}}{\dfrac{\cprob{\R}{T, \sigsq} \prob{T}}{\cancel{\cprob{\R}{\sigsq}}}} \\
&=& \underbrace{\frac{\prob{T^* \rightarrow T}}{\prob{T \rightarrow T^*}}}_{\text{transition ratio}} ~~~\times~~~ \underbrace{\frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}}}_{\text{likelihood ratio}} ~~~\times \underbrace{\frac{\prob{T^*}}{\prob{T}}}_{\text{tree structure ratio}}
\eeqn

\subsection*{Grow Proposal}

Let's pretend we're transitioning from $T \rightarrow T^*$ using a GROW step and let's analyze each of the above expressions one-by-one.

\subsubsection*{Transition Ratio}

So $\prob{T \rightarrow T^*}$ means the probability of transitioning from $T$ into the new tree proposal $T^*$. This would have to be equal to the following:

\beqn
\prob{T \rightarrow T^*} &=& \prob{\text{GROW}} \prob{\text{selecting the $\ell$th node to grow from}} \times \\
&& \prob{\text{selecting the $j$th attribute to split on}} \prob{\text{selecting the $i$th value to split on}}
\eeqn

We're picking from one of the terminal nodes, and then we're picking an attribute and split point, this becomes:

\beqn
\cprob{T^*}{T} &=& \prob{\text{GROW}} \oneover{b} \oneover{p_{adj}} \oneover{n_{adj}} \underbrace{\sum_{k=1}^{n_{adj}} \indic{X_{i_k j} = x^*}}_{\nrep} = \prob{\text{GROW}} \oneover{b} \oneover{p_{adj}} \frac{\nrep}{n_{adj}}
\eeqn

Now, $p_{adj}$ is the number of predictors left available to split on. This is \textit{from the perspective} of the $\ell$th node in tree $T$. Why would this be less than $p$? Because if you look up into the node's lineage, you may have already used all available split values for some attributes. Those would no longer be available to split from.

Then, $\indic{X_{i_k j} = x^*}$ is whether or not a particular value of column $j$ is equal to the split point, $x^*$ we've chosen. $n_{adj}$ is the number of values left in the column after adjusting for previous splits. We can obtain this adjusted row count by looking at the node's lineage for any splits on $j$ and then taking the minimum of those split values, and then finding the subset of the design matrix whose values are less than that minimum for column $j$. In order to compute $\sum_{k=1}^{n_{adj}} \indic{X_{i_k j} = x^*}$ which we denote for short as $\nrep$, we just count the number of values in the column that are equal to the split point.\\

So now $\prob{T^* \rightarrow T}$ is the probability of transitioning from the new tree back to the old tree which would be:

\beqn
\prob{T^* \rightarrow T} &=& \prob{\text{PRUNE}} \prob{\text{selecting the $\ell$th node to prune from}} \\
&=& \prob{\text{PRUNE}}\oneover{w_2^*}
\eeqn

Thus, the transition ratio will be:

\beqn
\frac{\prob{T^* \rightarrow T}}{\prob{T \rightarrow T^*}} = \frac{\prob{\text{PRUNE}}\oneover{w_2^*}}{\prob{\text{GROW}}\oneover{b} \oneover{p_{adj}} \frac{\nrep}{n_{adj}}} = \cancelto{?}{\frac{\prob{\text{PRUNE}}}{\prob{\text{GROW}}}} \frac{b ~ p_{adj} ~ n_{adj}}{w_2^* \nrep}
\eeqn

Why don't the probabilities of prune and grow cancel? Well, under the case where we cannot grow anymore (if we use all split variables), the probability of growth will be 0. Thus, those steps \textit{cannot} be considered since the ratio would be undefined. As long as they can be considered, that ratio will cancel. In log form, this becomes:

\inblue{
\beqn
\natlog{b} + \natlog{p_{adj}} + \natlog{n_{adj}} - \natlog{w_2^*} - \natlog{\nrep}
\eeqn
}

\subsubsection*{Likelihood Ratio}


What about the likelihood given the tree? The only reason you need the $T$ information is so we know which $R$ values fall in which of the leaves:

\beqn
\cprob{\Roneton}{T, \sigsq} = \prod_{\ell=1}^{b} \underbrace{\cprob{\Rlonetonl}{\sigsq}}
\eeqn

The r.h.s underbraces is the likelihood of each leaf separately which is \textit{not} dependent on $T$ anymore. We can multiply the likelihoods of each leaf because we assume the leaves are independent. The $R_\ell$'s are the data in the $\ell$th leaf and there is $n_\ell$ of them, the portion of $n$ in the leaf. Obviously, $n = \sum_{\ell=1}^b n_\ell$.\\

Let's look at the likelihood of a single leaf more carefully. We know that if we knew the mean at the leaf, which we denote $\mu_\ell$, we would have:

\beqn
\Rlonetonl | \mu_\ell, \sigsq ~\iid~ \normnot{\mu}{\sigsq}
\eeqn

This means that if we can margin out $\mu$, we can arrive at the expression that is needed for the calculation. Recall that one of the BART model assumptions is a prior on the average value of $\mu \sim \normnot{0}{\sigsq_\mu}$ and thus:

\beqn
\cprob{\Rlonetonl}{\sigsq} = \int_\reals \cprob{\Rlonetonl}{\mu, \sigsq} \prob{\mu; \sigsq_\mu} d\mu
\eeqn

Since the likelihoods are solely determined by the terminal nodes, the proposal tree differs from the original tree by only the $\ell$th node in the original becoming the $\ell_L$ and $\ell_R$ nodes in the proposal. Hence, the likelihood ratio becomes only:

\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} = \frac{\cprob{\RLlonetonlL}{\sigsq} \cprob{\RRlonetonlR}{\sigsq}}{\cprob{\Rlonetonl}{\sigsq}} \\
&=& \frac{\myint{\mu}{\reals}{}{\cprob{\RLlonetonlL}{\mu, \sigsq}\prob{\mu}} ~~ \myint{\mu}{\reals}{}{\cprob{\RRlonetonlR}{\mu, \sigsq}\prob{\mu}}}{\myint{\mu}{\reals}{}{\cprob{\Rlonetonl}{\mu, \sigsq}\prob{\mu}}}  \eqncomment{1}\\
\eeqn

I now present three strategies to perform the margining.

\subsubsection*{Strategy \#1 --- Convolution}

Let's take a more careful look at the non-margined leaf-likelihood expression and recall from basic mathematical statistics the result that the sample average, $\Rbar_\ell$, is a sufficient statistic for $\mu$ via the factorization theorem:


\begin{changemargin}{-0.5in}{0in}
\beqn
\prob{\Rlonetonl | \mu, \sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \mu}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \parens{n_\ell \squared{\Rbar_\ell - \mu} + \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} ~\exp{-\frac{n_\ell}{2\sigsq} \squared{\Rbar_\ell - \mu}} \\
&=& \underbrace{\oneoversqrt{n_\ell} \oneover{\tothepow{2\pi\sigsq}{\overtwo{n_\ell - 1}}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}}_h ~ \sqrt{\frac{n_\ell}{2\pi\sigsq}} ~\exp{-\frac{n_\ell}{2\sigsq} \squared{\Rbar_\ell - \mu}} \\
\eeqn
\end{changemargin}


So now we margin by integrating:

\begin{changemargin}{-0.5in}{0in}
\beqn
\cprob{\Rlonetonl}{\sigsq} &=& \int_\reals \prob{\Rlonetonl | \mu_\ell, \sigsq} \prob{\mu_\ell; \sigsq_\mu} d\mu_\ell \\
&=& h \underbrace{\int_\reals \sqrt{\frac{n_\ell}{2\pi\sigsq}} ~\exp{-\frac{n_\ell}{2\sigsq} \squared{\Rbar_\ell - \mu_\ell}} \oneoversqrt{2\pi\sigsq_\mu} ~\exp{-\oneover{2\sigsq_\mu} \musq}  d\mu_\ell}_{\text{the definition of a convolution}} \\
&=& h ~\normnot{0}{\frac{\sigsq}{n_\ell}} \star \normnot{0}{\sigsq_\mu} \\
&=& h ~ \normnot{0}{\frac{\sigsq}{n_\ell} + \sigsq_\mu} \eqncomment{with free variable $\Rbar_\ell$} \\
&=& h ~ \oneoversqrt{2\pi \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} ~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} \Rbar_\ell^2}\\
\eeqn
\end{changemargin}

%The problem here is that $g$ is not a likelihood. So I don't know how to do that margining trick with $\normnot{0}{\overn{\sigsq}} \star \normnot{0}{\sigsq_\mu} = \normnot{0}{\overn{\sigsq} + \sigsq_\mu}$. So I think I have to do the integral manually using Mathematica:
%
%\beqn
%\int_\reals g(\Rbar_\ell ~|~ \mu, \sigsq) \prob{\mu; \sigsq_\mu} d\mu &=& \int_\reals \exp{-\oneover{2\sigsq} \parens{-2n_\ell \mu \Rbar_\ell + n_\ell \musq}} \oneoversqrt{2\pi\sigsq_\mu} \exp{-\oneover{2\sigsq_\mu} \musq} d\mu \\
%&=& \oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} \exp{\frac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_\ell \sigsq_\mu}}} \\
%\Rightarrow \cprob{\Rlonetonl}{\sigsq} &\propto& \oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} \exp{\frac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_\ell \sigsq_\mu}}} \\
%\eeqn

%\begin{figure}
%\begin{center}
%\includegraphics[width=6in]{integrate_out_mu2.eps}
%\end{center}
%\end{figure}
%\FloatBarrier

%And this result does not appear to be equal to $\normnot{0}{\overn{\sigsq} + \sigsq_\mu}$. \\


%\beqn
%\cprob{\Rlonetonl}{\sigsq} = h(\Rlonetonl ~|~ \sigsq) \oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} \exp{\frac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\parens{\sigma^4 + n_\ell\sigsq \sigsq_\mu}}}
%\eeqn

So now we substitue the above result into equation 1:

\begin{changemargin}{-0.5in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \frac{h_L ~ \oneoversqrt{2\pi \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu}} ~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu}} \Rbar_{\ell_L}^2} h_R ~ \oneoversqrt{2\pi \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}} ~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}} \Rbar_{\ell_R}^2}}{h ~ \oneoversqrt{2\pi \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} ~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} \Rbar_\ell^2}} \\
&=& \frac{h_L h_R}{h}  \sqrt{\frac{\cancel{2\pi} \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}}{\cancel{2\pi} \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu} 2\pi \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}}} \frac{~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu}} \Rbar_{\ell_L}^2}  ~\exp{-\oneover{2 \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}} \Rbar_{\ell_R}^2}}{\exp{-\oneover{2 \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} \Rbar_\ell^2}} \\
&=& \frac{h_L h_R}{h}  \sqrt{\frac{ \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}}{ \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu} 2\pi \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}}} \exp{\oneover{2 \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} \Rbar_\ell^2 -\oneover{2 \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu}} \Rbar_{\ell_L}^2 -\oneover{2 \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}} \Rbar_{\ell_R}^2} \\
\eeqn
\end{changemargin}

%\beqn
%\frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} &=& h\parens{\RLlonetonlL ~|~ \sigsq} \oneoversqrt{\sigsq_\mu \parens{\frac{n_{\ell_L}}{\sigsq} + 1}} ~~\exp{\frac{n_{\ell_L}^2 \Rbar_{\ell_L}^2 \sigsq_\mu}{2\parens{\sigma^4 + n_{\ell_L}\sigsq \sigsq_\mu}}} \\
%&& ~~\times h\parens{\RRlonetonlR ~|~ \sigsq} \oneoversqrt{\sigsq_\mu \parens{\frac{n_{\ell_R}}{\sigsq} + 1}} ~~\exp{\frac{n_{\ell_R}^2 \Rbar_{\ell_R}^2 \sigsq_\mu}{2\parens{\sigma^4 + n_{\ell_R}\sigsq \sigsq_\mu}}} \\
%&& ~~\times \inverse{h\parens{\Rlonetonl ~|~ \sigsq} \oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} ~~\exp{\dfrac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\parens{\sigma^4 + n_\ell\sigsq \sigsq_\mu}}}} \\
%\eeqn

Let's examine the ratio of the $h$ functions:

\begin{changemargin}{-1in}{0in}
\beqn
&& \frac{h_L h_R}{h} = \frac{\doneoversqrt{n_{\ell_L}} \doneover{\tothepow{2\pi\sigsq}{\overtwo{n_{\ell_L} - 1}}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_{\ell_L}} \squared{R_{\ell_L, i} - \Rbar_{\ell_L}}} \doneoversqrt{n_{\ell_R}} \doneover{\tothepow{2\pi\sigsq}{\overtwo{n_{\ell_R} - 1}}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_{\ell_R}} \squared{R_{\ell_R, i} - \Rbar_{\ell,R}}}}{\doneoversqrt{n_\ell} \doneover{\tothepow{2\pi\sigsq}{\overtwo{n_\ell - 1}}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}} \\
\eeqn
\end{changemargin}

Now note that:

\beqn
\frac{\doneover{\tothepow{2\pi\sigsq}{\overtwo{n_{\ell_L} - 1}}} \doneover{\tothepow{2\pi\sigsq}{\overtwo{n_{\ell_R} - 1}}}}{\doneover{\tothepow{2\pi\sigsq}{\overtwo{n_\ell - 1}}}} = \frac{\tothepow{2\pi\sigsq}{\overtwo{n_\ell - 1}}}{\tothepow{2\pi\sigsq}{\overtwo{n_\ell - 2}}} = \sqrt{2\pi\sigsq}
\eeqn

Grouping the rest of the terms inside and outside of the exponentiation:

\beqn
\frac{h_L h_R}{h} &=& \sqrt{\frac{2\pi\sigsq n_\ell}{n_{\ell_L}n_{\ell_R}}} ~\exp{-\oneover{2\sigsq}\parens{\underbrace{\sum_{i=1}^{n_{\ell_L}} \squared{R_{\ell_L, i} - \Rbar_{\ell_L}} + \sum_{i=1}^{n_{\ell_R}} \squared{R_{\ell_R, i} - \Rbar_{\ell,R}} - \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}}}
\eeqn

Now let's take a look at the underbraced quantity:

\beqn
&=& \sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}^2 - 2n_{\ell_L}\Rbar_{\ell_L}^2 + n_{\ell_L}\Rbar_{\ell_L}^2 +\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}^2 - 2n_{\ell_R}\Rbar_{\ell_R}^2 + n_{\ell_R}\Rbar_{\ell_R}^2 - \sum_{i=1}^{n_{\ell}} R_{\ell, i}^2 + 2n_{\ell}\Rbar_{\ell}^2 - n_{\ell}\Rbar_{\ell}^2 \\
&=& \cancel{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}^2} - 2n_{\ell_L}\Rbar_{\ell_L}^2 + n_{\ell_L}\Rbar_{\ell_L}^2 + \cancel{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}^2} - 2n_{\ell_R}\Rbar_{\ell_R}^2 + n_{\ell_R}\Rbar_{\ell_R}^2 - \cancel{\sum_{i=1}^{n_{\ell}} R_{\ell, i}^2} + 2n_{\ell}\Rbar_{\ell}^2 - n_{\ell}\Rbar_{\ell}^2 \\
&=& n_{\ell}\Rbar_{\ell}^2 - n_{\ell_L}\Rbar_{\ell_L}^2 - n_{\ell_R}\Rbar_{\ell_R}^2
\eeqn

Thus, we can arrive at the $h$ ratio's final expression:

\beqn
\frac{h_L h_R}{h} &=& \sqrt{\frac{2\pi\sigsq n_\ell}{n_{\ell_L}n_{\ell_R}}} ~\exp{-\oneover{2\sigsq} \parens{n_{\ell}\Rbar_{\ell}^2 - n_{\ell_L}\Rbar_{\ell_L}^2 - n_{\ell_R}\Rbar_{\ell_R}^2}} \\
\eeqn

Now, putting it all together:

\begin{changemargin}{-0.5in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \sqrt{\frac{\cancel{2\pi} \sigsq n_\ell}{n_{\ell_L}n_{\ell_R}}} \sqrt{\frac{ \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}}{ \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu} \cancel{2\pi} \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}}} ~\exp{-\oneover{2\sigsq} \parens{n_{\ell}\Rbar_{\ell}^2 - n_{\ell_L}\Rbar_{\ell_L}^2 - n_{\ell_R}\Rbar_{\ell_R}^2}} \times \\
&& \exp{\half \parens{\oneover{\parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}} \Rbar_\ell^2 -\oneover{ \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu}} \Rbar_{\ell_L}^2 -\oneover{\parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}} \Rbar_{\ell_R}^2}} \\
&=& \sqrt{\frac{\sigsq n_\ell}{n_{\ell_L}n_{\ell_R}} \frac{ \parens{\frac{\sigsq}{n_\ell} + \sigsq_\mu}}{ \parens{\frac{\sigsq}{n_{\ell_L}} + \sigsq_\mu} \parens{\frac{\sigsq}{n_{\ell_R}} + \sigsq_\mu}}} ~\exp{\oneover{2\sigsq} \parens{n_{\ell_L}\Rbar_{\ell_L}^2 + n_{\ell_R}\Rbar_{\ell_R}^2 - n_{\ell}\Rbar_{\ell}^2}} \times \\
&&  \exp{\oneover{2\sigsq} \parens{\oneover{\parens{\frac{1}{n_\ell} + \frac{\sigsqmu}{\sigsq}}} \Rbar_\ell^2 -\oneover{\parens{\frac{1}{n_{\ell_L}} + \frac{\sigsqmu}{\sigsq}}} \Rbar_{\ell_L}^2 -\oneover{\parens{\frac{1}{n_{\ell_R}} + \frac{\sigsqmu}{\sigsq}}} \Rbar_{\ell_R}^2}} \\
&=& \underbrace{\sqrt{\frac{\sigsq \parens{\sigsq + \sigsq_\mu n_{\ell_L}}}{ \parens{\sigsq + \sigsq_\mu n_{\ell_L}} \parens{\sigsq + \sigsq_\mu n_{\ell_R}}}}}_c \times \\
&&  \exp{\oneover{2\sigsq} \parens{\parens{\oneover{\parens{\frac{1}{n_\ell} + \frac{\sigsqmu}{\sigsq}}} - n_\ell} \Rbar_\ell^2 -\parens{\oneover{\parens{\frac{1}{n_{\ell_L}} + \frac{\sigsqmu}{\sigsq}}} + n_{\ell_L}} \Rbar_{\ell_L}^2 - \parens{\oneover{\parens{\frac{1}{n_{\ell_R}} + \frac{\sigsqmu}{\sigsq}}} + n_{\ell_R}} \Rbar_{\ell_R}^2}} \\
&=& c ~\exp{\oneover{2\sigsq} \parens{-\parens{\frac{\frac{\sigsqmu n_{\ell}}{\sigsq}}{\parens{\frac{1}{n_\ell} + \frac{\sigsqmu}{\sigsq}}}} \Rbar_\ell^2 + \parens{\frac{\frac{\sigsqmu n_{\ell_L}}{\sigsq}}{\parens{\frac{1}{n_{\ell_L}} + \frac{\sigsqmu}{\sigsq}}}} \Rbar_{\ell_L}^2 + \parens{\frac{\frac{\sigsqmu n_{\ell_R}}{\sigsq}}{\parens{\frac{1}{n_{\ell_R}} + \frac{\sigsqmu}{\sigsq}}}} \Rbar_{\ell_R}^2}} \\
&=& c ~\exp{\oneover{2\sigsq} \parens{\parens{\frac{\sigsqmu n_{\ell_L}}{\parens{\frac{\sigsq}{n_{\ell_L}} + \sigsqmu}}} \Rbar_{\ell_L}^2 + \parens{\frac{\sigsqmu n_{\ell_R}}{\parens{\frac{\sigsq}{n_{\ell_R}} + \sigsqmu}}} \Rbar_{\ell_R}^2} - \parens{\frac{\sigsqmu n_{\ell}}{\parens{\frac{\sigsq}{n_\ell} + \sigsqmu}}} \Rbar_\ell^2} \\
&=& \sqrt{\frac{\sigsq \parens{\sigsq + \sigsq_\mu n_{\ell_L}}}{ \parens{\sigsq + \sigsq_\mu n_{\ell_L}} \parens{\sigsq + \sigsq_\mu n_{\ell_R}}}} \exp{\frac{\sigsqmu}{2\sigsq} \parens{ \frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\parens{\sigsq + n_{\ell_L}\sigsqmu}} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\parens{\sigsq + n_{\ell_R}\sigsqmu}} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\parens{\sigsq + n_\ell \sigsqmu}}}} \\
\eeqn
\end{changemargin}


\subsubsection*{Strategy \#2 --- Integral Computation in Mathematica}

Let's factorize the $\iid$ normal likelihood like the following:

\beqn
\prob{\Rlonetonl | \mu, \sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \mu}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2} \underbrace{\exp{-\oneover{2\sigsq} \parens{-2n_\ell \mu \Rbar_\ell + n_\ell \musq}}}_g \\
%&=& h(\Rlonetonl ~|~ \sigsq) \cdot g(\Rbar_\ell ~|~ \mu, \sigsq) \\
\eeqn

Now, let's try to build the ratio:

\small
\begin{changemargin}{-1in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \frac{\cprob{\RLlonetonlL}{\sigsq} \cprob{\RRlonetonlR}{\sigsq}}{\cprob{\Rlonetonl}{\sigsq}} \\
&=& \frac{\myint{\mu}{\reals}{}{\cprob{\RLlonetonlL}{\mu, \sigsq}\prob{\mu}} ~~ \myint{\mu}{\reals}{}{\cprob{\RRlonetonlR}{\mu, \sigsq}\prob{\mu}}}{\myint{\mu}{\reals}{}{\cprob{\Rlonetonl}{\mu, \sigsq}\prob{\mu}}} \\
&=& \frac{\oneover{\tothepow{2\pi\sigsq}{n_{\ell_L} / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_{\ell_L}} R_{{\ell_L}_i}^2} \parens{\myint{\mu}{\reals}{}{g_{\ell_L} \prob{\mu}}}~ \oneover{\tothepow{2\pi\sigsq}{n_{\ell_R} / 2}}  ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_{\ell_R}} R_{{\ell_R}_i}^2} \parens{\myint{\mu}{\reals}{}{g_{\ell_R} \prob{\mu}}}}{\oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2} \parens{\myint{\mu}{\reals}{}{g_{\ell} \prob{\mu}}}} \\
&=& \frac{\cancel{\oneover{\tothepow{2\pi\sigsq}{n_{\ell_L} / 2}}} ~\cancel{\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_{\ell_L}} R_{{\ell_L}_i}^2}} \parens{\myint{\mu}{\reals}{}{g_{\ell_L} \prob{\mu}}}~ \cancel{\oneover{\tothepow{2\pi\sigsq}{n_{\ell_R} / 2}}}  ~\cancel{\exp{-\oneover{2\sigsq}} \sum_{i=1}^{n_{\ell_R}} R_{{\ell_R}_i}^2} \parens{\myint{\mu}{\reals}{}{g_{\ell_R} \prob{\mu}}}}{\cancel{\oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}}} ~\cancel{\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2}} \parens{\myint{\mu}{\reals}{}{g_{\ell} \prob{\mu}}}} \\
&=& \frac{\myint{\mu}{\reals}{}{g_{\ell_L} \prob{\mu}} \myint{\mu}{\reals}{}{g_{\ell_R} \prob{\mu}}}{\myint{\mu}{\reals}{}{g_{\ell} \prob{\mu}}} \\
&=& \frac{\myint{\mu}{\reals}{}{g_{\ell_L} \cancel{\oneoversqrt{2\pi\sigsqmu}} \exp{-\oneover{2\sigsqmu} \musq}} \myint{\mu}{\reals}{}{g_{\ell_R} \oneoversqrt{2\pi\sigsq_\mu} \exp{-\oneover{2\sigsqmu} \musq}}}{\myint{\mu}{\reals}{}{g_{\ell} \cancel{\oneoversqrt{2\pi\sigsq_\mu}} \exp{-\oneover{2\sigsqmu} \musq}}} \\
&=& \oneoversqrt{2\pi\sigsq_\mu} \frac{\myint{\mu}{\reals}{}{\exp{-\oneover{2\sigsq} \parens{-2n_{\ell_L} \mu \Rbar_{\ell_L} + n_{\ell_L} \musq}} \exp{-\oneover{2\sigsqmu} \musq}} \myint{\mu}{\reals}{}{\exp{-\oneover{2\sigsq} \parens{-2n_{\ell_L} \mu \Rbar_{\ell_L} + n_{\ell_L} \musq}}  \exp{-\oneover{2\sigsqmu} \musq}}}{\underbrace{\myint{\mu}{\reals}{}{\exp{-\oneover{2\sigsq} \parens{-2n_\ell \mu \Rbar_\ell + n_\ell \musq}} \exp{-\oneover{2\sigsqmu} \musq}}}} \\
\eeqn
\end{changemargin}
\normalsize

Let's evaluate the underbraced integral using Mathematica:

%The problem here is that $g$ is not a likelihood. So I don't know how to do that margining trick with $\normnot{0}{\overn{\sigsq}} \star \normnot{0}{\sigsq_\mu} = \normnot{0}{\overn{\sigsq} + \sigsq_\mu}$. So I think I have to do the integral manually using Mathematica:

\beqn
\int_\reals g(\Rbar_\ell ~|~ \mu, \sigsq) \prob{\mu; \sigsq_\mu} d\mu &=& \int_\reals \exp{-\oneover{2\sigsq} \parens{-2n_\ell \mu \Rbar_\ell + n_\ell \musq}} \exp{-\oneover{2\sigsq_\mu} \musq} d\mu \\
&=& \sqrt{\frac{2\pi}{\frac{n_\ell}{\sigsq} + \oneover{\sigsqmu}}} \exp{\frac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_\ell \sigsq_\mu}}} \\
%\Rightarrow \cprob{\Rlonetonl}{\sigsq} &\propto& \oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} \exp{\frac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_\ell \sigsq_\mu}}} \\
\eeqn

So now we have:

\small
\begin{changemargin}{-1in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \oneoversqrt{\cancel{2\pi}\sigsq_\mu} \frac{\sqrt{\dfrac{\cancel{2\pi}}{\frac{n_{\ell_L}}{\sigsq} + \oneover{\sigsqmu}}} \exp{\dfrac{n_{\ell_L}^2 \Rbar_{\ell_L}^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_{\ell_L} \sigsq_\mu}}} \sqrt{\dfrac{\cancel{2\pi}}{\frac{n_{\ell_R}}{\sigsq} + \oneover{\sigsqmu}}} \exp{\dfrac{n_{\ell_R}^2 \Rbar_{\ell_R}^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_{\ell_R} \sigsq_\mu}}}}{\sqrt{\dfrac{\cancel{2\pi}}{\frac{n_\ell}{\sigsq} + \oneover{\sigsqmu}}} \exp{\dfrac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\sigsq\parens{\sigsq + n_\ell \sigsq_\mu}}}} \\
&=& \sqrt{\frac{\frac{n_\ell}{\sigsq} + \oneover{\sigsqmu}}{\sigsqmu \parens{\frac{n_{\ell_L}}{\sigsq} + \oneover{\sigsqmu}}\parens{\frac{n_{\ell_R}}{\sigsq} + \oneover{\sigsqmu}}}} ~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{n_{\ell_L}^2 \Rbar_{\ell_L}^2}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{n_{\ell_R}^2 \Rbar_{\ell_R}^2}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{n_\ell^2 \Rbar_\ell^2}{\sigsq + n_\ell \sigsq_\mu}}} \\
&=& \sqrt{\frac{\sigsq \parens{\sigsq + n_\ell \sigsqmu}}{\parens{\sigsq + n_{\ell_L} \sigsqmu}\parens{\sigsq + n_{\ell_R} \sigsqmu}}}~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu}}} \\
\eeqn
\end{changemargin}
\normalsize

%\begin{figure}
%\begin{center}
%\includegraphics[width=6in]{integrate_out_mu2.eps}
%\end{center}
%\end{figure}
%\FloatBarrier


%\beqn
%&& \frac{h\parens{\RLlonetonlL ~|~ \sigsq}h\parens{\RRlonetonlR ~|~ \sigsq}}{h\parens{\Rlonetonl ~|~ \sigsq}} \\
%&=& \frac{\doneover{\tothepow{2\pi\sigsq}{n_{\ell_L} / 2}} ~\exp{-\doneover{2\sigsq} \sum_{i=1}^{n_{\ell_L}} R_{\ell_i}^2} \doneover{\tothepow{2\pi\sigsq}{n_{\ell_R} / 2}} ~\exp{-\doneover{2\sigsq} \sum_{i=1}^{n_{\ell_R}} R_{\ell_i}^2}}{\doneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\doneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2}} \\
%&=& \frac{\doneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\doneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2}}{\doneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\doneover{2\sigsq} \sum_{i=1}^{n_\ell} R_{\ell_i}^2}} = 1 \eqncomment{since $n_\ell = n_{\ell_R} + n_{\ell_L}$}
%\eeqn


%\begin{changemargin}{-0.5in}{0in}
%\beqn
%\frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} &=& \frac{\oneoversqrt{\sigsq_\mu \parens{\frac{n_{\ell_L}}{\sigsq} + 1}} \oneoversqrt{\sigsq_\mu \parens{\frac{n_{\ell_R}}{\sigsq} + 1}} ~~\exp{\dfrac{n_{\ell_L}^2 \Rbar_{\ell_L}^2 \sigsq_\mu}{2\parens{\sigma^4 + n_{\ell_L}\sigsq \sigsq_\mu}}} ~~\exp{\dfrac{n_{\ell_R}^2 \Rbar_{\ell_R}^2 \sigsq_\mu}{2\parens{\sigma^4 + n_{\ell_R}\sigsq \sigsq_\mu}}}}{\oneoversqrt{\sigsq_\mu \parens{\frac{n_\ell}{\sigsq} + 1}} ~~\exp{\dfrac{n_\ell^2 \Rbar_\ell^2 \sigsq_\mu}{2\parens{\sigma^4 + n_\ell\sigsq \sigsq_\mu}}}} \\
%&=& \sqrt{\frac{\sigsq \parens{n_\ell + \sigsq}}{\sigsq_\mu \parens{n_{\ell_L} + \sigsq}\parens{n_{\ell_R} + \sigsq}}} ~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\overbrace{n_{\ell_L}^2 \Rbar_{\ell_L}^2}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\overbrace{n_{\ell_R}^2 \Rbar_{\ell_R}^2}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\overbrace{n_\ell^2 \Rbar_\ell^2}}{\sigsq + n_\ell \sigsq_\mu}}} \\
%\eeqn
%\end{changemargin}

%Note how the ratio is only a function of the $\sum R_i$'s which makes calculations efficient.

%Let's think about what's really driving this ratio. Consider $\sigsq = \sigsqmu = 1$ and $n_\ell = 10$ with an equal split in left and right daughter leaves. That would mean that the ratio would be:
%
%\beqn
%\sqrt{\frac{11}{36}}~~\exp{\half \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{6} + \frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_R, i}}}{6} - \frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell, i}}}{11}}} \\
%\eeqn



\subsubsection*{Strategy \#3 --- Completing the Square}

Recall that:

\begin{changemargin}{-0.5in}{0in}
\beqn
\prob{\Rlonetonl | \mu, \sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \mu}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \parens{n_\ell \squared{\Rbar_\ell - \mu} + \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} ~\exp{-\frac{n_\ell}{2\sigsq} \squared{\Rbar_\ell - \mu}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} ~\exp{-\frac{n_\ell}{2\sigsq} \parens{\Rbar_\ell^2 - 2\Rbar_\ell \mu + \musq}} \\
\eeqn
\end{changemargin}

which means that:

\beqn
\cprob{\Rlonetonl}{\sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \times \\
&& \myint{\mu}{\reals}{}{\exp{-\frac{n_\ell}{2\sigsq} \parens{\Rbar_\ell^2 - 2\Rbar_\ell \mu + \musq}}\oneoversqrt{2\pi\sigsq_\mu}\exp{-\oneover{2\sigsqmu} \musq}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \times \\
&& \oneoversqrt{2\pi\sigsq_\mu} \myint{\mu}{\reals}{}{\exp{-\frac{n_\ell}{2\sigsq} \parens{\Rbar_\ell^2 - 2\Rbar_\ell \mu + \musq} -\oneover{2\sigsqmu} \musq}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \times \\
&& \oneoversqrt{2\pi\sigsq_\mu} \myint{\mu}{\reals}{}{\exp{\underbrace{\parens{-\frac{n_\ell}{2\sigsq} - \oneover{2\sigsqmu}}\musq + \parens{\frac{\Rbar_\ell n_\ell}{\sigsq}} \mu} - \frac{n_\ell \Rbar_\ell^2}{2\sigsq}}} \\
\eeqn

Now let's complete the square of the underbraced above. We want it to look like $c\squared{d-\mu} = c\musq - 2cd\mu + cd^2$. Already we have $c$, the factor multiplying $\musq$, so then $d$ becomes (using the $\mu$ term above):

\beqn
d = \frac{\Rbar_\ell n_\ell}{-2c\sigsq} = \frac{\Rbar_\ell n_\ell}{-2 \parens{-\frac{n_\ell}{2\sigsq} - \oneover{2\sigsqmu}} \sigsq} = \frac{\Rbar_\ell n_\ell}{n_\ell + \frac{\sigsq}{\sigsqmu}}
\eeqn

and the final $cd^2$ term becomes:

\beqn
cd^2 = c \squaredfrac{\Rbar_\ell n_\ell}{-2c\sigsq} = \frac{\Rbar_\ell^2 n_\ell^2}{4c \sigma^4} =  \frac{\Rbar_\ell^2 n_\ell^2}{4\parens{-\frac{n_\ell}{2\sigsq} - \oneover{2\sigsqmu}} \sigma^4} = \frac{\Rbar_\ell^2 n_\ell^2}{-2\parens{\frac{n_\ell}{\sigsq} + \oneover{\sigsqmu}} \sigma^4} = \frac{\Rbar_\ell^2 n_\ell^2}{-2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}
\eeqn

Returning to our margined expression, we subtract and add the $cd^2$ term inside the exponentiation:

\small
\begin{changemargin}{-0.5in}{0in}
\beqn
\cprob{\Rlonetonl}{\sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \oneoversqrt{2\pi\sigsq_\mu}\times \\
&&  \myint{\mu}{\reals}{}{\exp{\underbrace{\parens{-\frac{n_\ell}{2\sigsq} - \oneover{2\sigsqmu}}\musq + \parens{\frac{\Rbar_\ell}{\sigsq}} \mu - \frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}} + \frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}} - \frac{n_\ell \Rbar_\ell^2}{2\sigsq}} } \\
\eeqn
\end{changemargin}
\normalsize

So the underbraced is the ``square'' and we pull the last two terms out (because they are not functions of $\mu$) to arrive at:

\begin{changemargin}{-0.5in}{0in}
\beqn
\cprob{\Rlonetonl}{\sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \oneoversqrt{2\pi\sigsq_\mu} \times \\
&& ~\exp{\frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}- \frac{n_\ell \Rbar_\ell^2}{2\sigsq}} \myint{\mu}{\reals}{}{\exp{\parens{\underbrace{-\frac{n_\ell}{2\sigsq} - \oneover{2\sigsqmu}}}\squared{\mu - \frac{\Rbar_\ell}{n_\ell + \frac{\sigsq}{\sigsqmu}}}}} \\
\eeqn
\end{changemargin}

Note how the integral is now the Gaussian integral with the $-\oneover{2\sigsq_*}$ parameter underbraced. Hence it will integrate to $\sqrt{2\pi\sigsq_*}$ and the expression becomes:

\begin{changemargin}{-0.5in}{0in}
\beqn
\cprob{\Rlonetonl}{\sigsq} &=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} ~\exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \times \\
&& \oneoversqrt{2\pi\sigsq_\mu} ~\exp{\frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}- \frac{n_\ell \Rbar_\ell^2}{2\sigsq}} \sqrt{2\pi \oneover{\frac{n_\ell}{\sigsq} + \oneover{\sigsqmu}}} \\
&=& \oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}} \sqrt{ \frac{\sigsq}{\sigsq + n_\ell \sigsqmu}}  \times \\
&& \exp{-\oneover{2\sigsq} \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}} \exp{\frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}- \frac{n_\ell \Rbar_\ell^2}{2\sigsq}} \\
\eeqn
\end{changemargin}

So now we're ready to calculate the likelihood ratio.

\begin{changemargin}{-0.75in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \frac{\cprob{\RLlonetonlL}{\sigsq} \cprob{\RRlonetonlR}{\sigsq}}{\cprob{\Rlonetonl}{\sigsq}} \\
&=& \frac{\cancel{\oneover{\tothepow{2\pi\sigsq}{n_{\ell_L} / 2}}} ~ \exp{\frac{\Rbar_{\ell_L}^2 n_\ell^2}{2\sigsq\parens{n_{\ell_L} + \frac{\sigsq}{\sigsqmu}}}- \frac{n_{\ell_L} \Rbar_{\ell_L}^2 }{2\sigsq}} \sqrt{ \frac{\cancel{\sigsq}}{\sigsq + n_{\ell_L} \sigsqmu}} \cancel{\oneover{\tothepow{2\pi\sigsq}{n_{\ell_R} / 2}}} ~ \exp{\frac{\Rbar_{\ell_R}^2 n_\ell^2}{2\sigsq\parens{n_{\ell_R} + \frac{\sigsq}{\sigsqmu}}}- \frac{n_{\ell_R} \Rbar_{\ell_R}^2}{2\sigsq}} \sqrt{ \frac{\sigsq}{\sigsq + n_{\ell_R} \sigsqmu}} }{\cancel{\oneover{\tothepow{2\pi\sigsq}{n_\ell / 2}}} ~ \exp{\frac{\Rbar_\ell^2 n_\ell^2}{2\sigsq\parens{n_\ell + \frac{\sigsq}{\sigsqmu}}}- \frac{n_\ell \Rbar_\ell^2}{2\sigsq}} \sqrt{ \frac{\cancel{\sigsq}}{\sigsq + n_\ell \sigsqmu}}} \times \\
&& \exp{\underbrace{-\oneover{2\sigsq}\parens{\sum_{i=1}^{n_{\ell_L}} \squared{R_{\ell_L, i} - \Rbar_{\ell_L}} + \sum_{i=1}^{n_{\ell_R}} \squared{R_{\ell_R, i} - \Rbar_{\ell,R}} - \sum_{i=1}^{n_\ell} \squared{R_{\ell_i} - \Rbar_\ell}}}}
\eeqn
\end{changemargin}

We've calculate the underbraced before in the strategy \#1 section. We now substitute, factor, and collect terms:

\beqn
&=& \underbrace{\sqrt{\frac{\sigsq \parens{\sigsq + n_\ell \sigsqmu}}{\parens{\sigsq + n_{\ell_L} \sigsqmu}\parens{\sigsq + n_{\ell_R} \sigsqmu}}}}_c  \times \\ 
&& \exp{\oneover{2\sigsq} \parens{\frac{\Rbar_{\ell_L}^2 n_{\ell_L}^2}{\parens{n_{\ell_L} + \frac{\sigsq}{\sigsqmu}} }- n_{\ell_L}\Rbar_{\ell_L}^2 + \frac{\Rbar_{\ell_R}^2 n_{\ell_R}^2}{\parens{n_{\ell_R} + \frac{\sigsq}{\sigsqmu}}}- n_{\ell_R}\Rbar_{\ell_R}^2 - \frac{\Rbar_{\ell}^2 n_\ell^2}{\parens{n_{\ell} + \frac{\sigsq}{\sigsqmu}}} + n_\ell\Rbar_\ell^2}} \times \\
&& \exp{\oneover{2\sigsq} \parens{n_{\ell_L}\Rbar_{\ell_L}^2 + n_{\ell}\Rbar_{\ell}^2 - n_{\ell}\Rbar_{\ell}^2}} \\
&=& c~\exp{\frac{\sigsqmu}{2\sigsq} \parens{\parens{\frac{n_{\ell_L}^2}{\sigsqmu n_{\ell_L} +\sigsq}} \Rbar_{\ell_L}^2 + \parens{\frac{n_{\ell_R}^2}{\sigsqmu n_{\ell_R} + \sigsq}} \Rbar_{\ell_R}^2 - \parens{\frac{n_\ell^2}{\sigsqmu n_{\ell} + \sigsq}} \Rbar_{\ell}^2}} \\
&=& \sqrt{\frac{\sigsq \parens{\sigsq + n_\ell \sigsqmu}}{\parens{\sigsq + n_{\ell_L} \sigsqmu}\parens{\sigsq + n_{\ell_R} \sigsqmu}}}~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu}}} \\
\eeqn

We've now computed this using three different methods, so it must be correct?\\

In log form, this becomes:

\inblue{
\beqn
&& \half \parens{\natlog{\sigsq} +\natlog{\sigsq + n_\ell \sigsqmu} -\natlog{\sigsq + n_{\ell_L} \sigsqmu} - \natlog{\sigsq + n_{\ell_R} \sigsqmu}} + \\
&& \frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu}}
\eeqn
}

\subsubsection*{Tree Structure Ratio}

Remember the prior form on trees: 

\beqn
\prob{T} &=& \prod_{\eta \in \Hleaves} \parens{1 - \prob{\text{splitting~} \eta}}  \prod_{\eta \in \Hint} \prob{\text{splitting~} \eta} \prod_{\eta \in \Hint} \prob{\text{rule~} \eta} \\
\eeqn

Remember from CGM98 that the probability of splitting on a given node $\eta$ is driven by two hyperparameters, $\alpha$ and $\beta$ in the following way where $d_\eta$ is the depth of the $\eta$ node:

\beqn
\prob{\text{splitting~} \eta} = \frac{\alpha}{\tothepow{1 + d_\eta}{\beta}}
\eeqn

The probability of assigning the specific rule, $\prob{\text{rule~} \eta}$, is just picking from all available attributes and then from all available unique splits with the modifications discussed in the previous section. Once again, the proposal tree differs from the original tree by only the $\ell$th node in the original becoming the $\ell_L$ and $\ell_R$ nodes in the proposal. This simplifies the tree structure ratio to just:

\beqn
\frac{\prob{T^*}}{\prob{T}} &=& \frac{\parens{1 - \prob{\text{splitting~} \eta_L}} \parens{1 - \prob{\text{splitting~} \eta_R}} \prob{\text{splitting~} \eta} \prob{\text{rule~} \eta}}{\parens{1 - \prob{\text{splitting~} \eta}}}\\
&=& \frac{\parens{1 - \dfrac{\alpha}{\tothepow{1 + d_{\eta_L}}{\beta}}}\parens{1 - \dfrac{\alpha}{\tothepow{1 + d_{\eta_R}}{\beta}}} \dfrac{\alpha}{\tothepow{1 + d_{\eta}}{\beta}} \doneover{p_{adj}}\dfrac{\nrep}{n_{adj}}}{1 -\dfrac{\alpha}{\tothepow{1 + d_{\eta}}{\beta}}} \\
&=& \alpha \frac{\squared{1 - \frac{\alpha}{\tothepow{2 + d_\eta}{\beta}}} \nrep}{\parens{\tothepow{1+d_\eta}{\beta} - \alpha} p_{adj} n_{adj}}
\eeqn

With the last line following from the fact that the depth of the child nodes is just the depth of the parent node incremented by 1. In log form this becomes:

\inblue{
\beqn
&&\natlog{\alpha} + 2 \natlog{1 - \frac{\alpha}{\tothepow{2 + d_\eta}{\beta}}} + \natlog{\nrep} - \natlog{\tothepow{1+d_\eta}{\beta} - \alpha} - \natlog{p_{adj}} - \natlog{n_{adj}}
\eeqn
}

Now we have a way of calculating $r$ for grow proposals by multiplying all three above results.\\

\subsection*{Prune Proposal}

\subsubsection*{Transition Ratio}

For prune proposals, we move in the opposite direction.  We need to hack off a node:

\beqn
\prob{T \rightarrow T^*} &=& \prob{\text{PRUNE}} \prob{\text{selecting the $\ell$th node to prune from}} \\
&=& \prob{\text{PRUNE}}\oneover{w_2}
\eeqn

To go the opposite direction, we need to make sure we grow the exact same node so $p_{adj}, n_{adj}$ need to be calculated based on whatever the $\ell$th node originally was:

\beqn
\prob{T^* \rightarrow T} &=& \prob{\text{GROW}} \prob{\text{selecting the $\ell$th node to grow from}} \times \\
&& \prob{\text{selecting the original attribute to split on}} \times \\
&& \prob{\text{selecting the original value to split on}} \\
&=& \prob{\text{GROW}} \oneover{b-1} \oneover{p_{adj}} \frac{\nrep}{n_{adj}}
\eeqn

We're using $b-1$ here because the proposed tree has one less terminal node due to the pruning than the original tree $T$ had.\\

Thus, the transition ratio becomes:

\beqn
\frac{\prob{T^* \rightarrow T}}{\prob{T \rightarrow T^*}} = \frac{\prob{\text{GROW}}  \oneover{b-1}\oneover{p_{adj}} \frac{\nrep}{n_{adj}}}{ \prob{\text{PRUNE}}\oneover{w_2}} = \cancelto{?}{\frac{\prob{\text{GROW}}}{\prob{\text{PRUNE}}}} \frac{w_2  \nrep}{(b-1) p_{adj} n_{adj}}
\eeqn

and in log form this becomes:

\inblue{
\beqn
\natlog{w_2} +\natlog{\nrep} - \natlog{b - 1} - \natlog{p_{adj}} - \natlog{n_{adj}}
\eeqn
}

Once again, we need to bookkeep and make sure we can actually prune this node. If it's just a root node, then we can't even consider this step at all. Otherwise, they'll cancel.

\subsubsection*{Likelihood Ratio}

It is pretty obvious this is the inverse of the grow step's likelihood ratio. Now the tree proposal has just one collapsed node where the original has a left and right component:

\begin{changemargin}{-0.5in}{0in}
\beqn
&& \frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} \\
&=& \inverse{\sqrt{\frac{\sigsq \parens{\sigsq + n_\ell \sigsqmu}}{\parens{\sigsq + n_{\ell_L} \sigsqmu}\parens{\sigsq + n_{\ell_R} \sigsqmu}}}~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu}}}} \\
&=& \sqrt{\frac{\parens{\sigsq + n_{\ell_L} \sigsqmu}\parens{\sigsq + n_{\ell_R} \sigsqmu}}{\sigsq \parens{\sigsq + n_\ell \sigsqmu}}} ~~\exp{\frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu}}} \\
\eeqn
\end{changemargin}

and in log form:

\inblue{
\beqn
&& \half \parens{\natlog{\sigsq + n_{\ell_L} \sigsqmu} + \natlog{\sigsq + n_{\ell_R} \sigsqmu} - \natlog{\sigsq} - \natlog{\sigsq + n_\ell \sigsqmu} } + \\
&& \frac{\sigsq_\mu}{2\sigsq} \parens{\frac{\squared{\sum_{i=1}^{n_{\ell_L}} R_{\ell_L, i}}}{\sigsq + n_{\ell_L}\sigsq_\mu} + \frac{\squared{\sum_{i=1}^{n_{\ell_R}} R_{\ell_R, i}}}{\sigsq + n_{\ell_R}\sigsq_\mu} - \frac{\squared{\sum_{i=1}^{n_{\ell}} R_{\ell, i}}}{\sigsq + n_\ell \sigsq_\mu}}
\eeqn
}

\subsubsection*{Tree Structure Ratio}

It is also clear this is just the inverse of the tree structure ratio for the grow step.

\beqn
\frac{\prob{T^*}}{\prob{T}} &=& \inverse{\alpha \frac{\squared{1 - \frac{\alpha}{\tothepow{2 + d_\eta}{\beta}}}\nrep}{\parens{\tothepow{1+d_\eta}{\beta} - \alpha} p_{adj} n_{adj}}}\\
&=& \frac{\parens{\tothepow{1+d_\eta}{\beta} - \alpha} p_{adj} n_{adj}}{\alpha\squared{1 - \frac{\alpha}{\tothepow{2 + d_\eta}{\beta}}}\nrep}
\eeqn


In log form this becomes:

\inblue{
\beqn
\natlog{\tothepow{1+d_\eta}{\beta} - \alpha} + \natlog{p_{adj}} + \natlog{n_{adj}} -\natlog{\alpha} - 2 \natlog{1 - \frac{\alpha}{\tothepow{2 + d_\eta}{\beta}}} - \natlog{\nrep}
\eeqn
}

\subsection*{Change}

Change would be picking one father node (a node with two leaves and no nodes of their own) and picking a new rule (\ie a new split attribute and new split value). Let's establish some new notation for this section:


\begin{itemize}
\item $\eta, \eta_*$ --- the node destined to be changed on the original tree $T$ and the proposed tree $T^*$.
\item $\etaone, \etatwo$ --- the left and right nodes on tree $T$ whose parent was chosen to be changed.
\item $\etaonestar, \etatwostar$ --- the left and right nodes on tree $T^*$ after the parent was changed.
\item $\Rones$ --- the residuals in the left leaf on tree $T$ whose parent was chosen to be changed.
\item $\Rtwos$ --- the residuals in the right leaf on tree $T$ whose parent was chosen to be changed.
\item $\Ronestars$ --- the residuals in the left leaf on tree $T^*$ after the parent was changed.
\item $\Rtwostars$ --- the residuals in the right leaf on tree $T^*$ after the parent was changed.
\item $\Ronebar$ --- the mean of the residuals on the left node on tree $T$ whose parent was chosen to be changed.
\item $\Rtwobar$ --- the mean of the residuals on the right node on tree $T$ whose parent was chosen to be changed.
\item $\Ronebarstar$ --- the mean of the residuals on the left node on tree $T^*$ after the parent was changed.
\item $\Rtwobarstar$ --- the mean of the residuals on the right node on tree $T^*$ after the parent was changed.
\end{itemize}

\subsubsection*{Transition Ratio}

We're looking at two simple transitions:

\beqn
\prob{T \rightarrow T^*} &=& \prob{\text{CHANGE}} \prob{\text{selecting $\eta$ to change}} \times \\
&& \prob{\text{selecting the new attribute to split on}} \times \\
&& \prob{\text{selecting the new value to split on}} \\
&=& \prob{\text{CHANGE}} \oneover{b} \oneover{p_{adj}} \frac{\nrepstar}{\nadjstar} \\
\prob{T^* \rightarrow T} &=& \prob{\text{CHANGE}} \prob{\text{selecting $\etastar$ to change}} \times \\
&& \prob{\text{selecting the original attribute to split on}} \times \\
&& \prob{\text{selecting the original value to split on}} \\
&=& \prob{\text{CHANGE}} \oneover{b} \oneover{p_{adj}} \frac{\nrep}{\nadj} \\
\eeqn

It is obvious that the majority of the above will cancel below to produce the ratio:

\beqn
\frac{\prob{T^* \rightarrow T^*}}{\prob{T \rightarrow T^*}} = \frac{\nrep}{\nrepstar} \frac{\nadjstar}{\nadj}
\eeqn


\subsubsection*{Likelihood Ratio}

The proposal tree differs from the original by just having two different leaves where the residuals are apportioned differently. We begin with direct substitution to quantities derived previously:

\beqn
\frac{\cprob{\R}{T^*, \sigsq}}{\cprob{\R}{T, \sigsq}} &=& \frac{\cprob{\Ronestars}{\sigsq}\cprob{\Rtwostars}{\sigsq}}{\cprob{\Rones}{\sigsq}\cprob{\Rtwos}{\sigsq}} \\
&=& \frac{\exp{-\oneover{2\sigsq} \sum_{i=1}^{\nonestar} \squared{R_{1^*,i} - \Ronebarstar}} \exp{\frac{\Ronebarstar^2 \nonestar^2}{2\sigsq\parens{\nonestar + \frac{\sigsq}{\sigsqmu}}}- \frac{\nonestar \Ronebarstar^2}{2\sigsq}}}{\exp{-\oneover{2\sigsq} \sum_{i=1}^{\none} \squared{R_{1,i} - \Ronebar}} \exp{\frac{\Ronebar^2 \none^2}{2\sigsq\parens{\none + \frac{\sigsq}{\sigsqmu}}}- \frac{\none \Ronebar^2}{2\sigsq}}} \times \\
&& \frac{\exp{-\oneover{2\sigsq} \sum_{i=1}^{\ntwostar} \squared{R_{2^*,i} - \Rtwobarstar}} \exp{\frac{\Rtwobarstar^2 \ntwostar^2}{2\sigsq\parens{\ntwostar + \frac{\sigsq}{\sigsqmu}}}- \frac{\ntwostar \Rtwobarstar^2}{2\sigsq}}}{\exp{-\oneover{2\sigsq} \sum_{i=1}^{\ntwo} \squared{R_{1,i} - \Rtwobar}} \exp{\frac{\Rtwobar^2 \none^2}{2\sigsq\parens{\ntwo + \frac{\sigsq}{\sigsqmu}}}- \frac{\ntwo \Rtwobar^2}{2\sigsq}}}
\eeqn

The first exponential term can be combined among all four quantities and the second exponential term can be combined among all four quantities to yield:

\beqn
&=& \exp{\oneover{2\sigsq} \parens{\nonestar \Ronebarstar^2 + \ntwostar \Rtwobarstar^2 - \none \Ronebar^2 - \ntwo \Rtwobar^2}} \times \\
&& \exp{\frac{\Ronebarstar^2 \nonestar^2}{2\sigsq\parens{\nonestar + \frac{\sigsq}{\sigsqmu}}}- \frac{\nonestar \Ronebarstar^2}{2\sigsq} + \frac{\Rtwobarstar^2 \ntwostar^2}{2\sigsq\parens{\ntwostar + \frac{\sigsq}{\sigsqmu}}}- \frac{\ntwostar \Rtwobarstar^2}{2\sigsq}} \times \\
&& \exp{-\frac{\Ronebar^2 \none^2}{2\sigsq\parens{\none + \frac{\sigsq}{\sigsqmu}}} + \frac{\none \Ronebar^2}{2\sigsq} - \frac{\Rtwobar^2 \none^2}{2\sigsq\parens{\ntwo + \frac{\sigsq}{\sigsqmu}}} + \frac{\ntwo \Rtwobar^2}{2\sigsq}}
\eeqn

Factoring out the $\oneover{2\sigsq}$, we see that the top row cancels and we arrive at:

\beqn
\exp{\oneover{2\sigsq} \parens{\frac{\Ronebarstar^2 \nonestar^2}{\nonestar + \frac{\sigsq}{\sigsqmu}} + \frac{\Rtwobarstar^2 \ntwostar^2}{\ntwostar + \frac{\sigsq}{\sigsqmu}} - \frac{\Ronebar^2 \none^2}{\none + \frac{\sigsq}{\sigsqmu}} - \frac{\Rtwobar^2 \none^2}{\ntwo + \frac{\sigsq}{\sigsqmu}}}}
\eeqn

which in log form is just simply:

\inblue{
\beqn
\oneover{2\sigsq} \parens{\frac{\Ronebarstar^2 \nonestar^2}{\nonestar + \frac{\sigsq}{\sigsqmu}} + \frac{\Rtwobarstar^2 \ntwostar^2}{\ntwostar + \frac{\sigsq}{\sigsqmu}} - \frac{\Ronebar^2 \none^2}{\none + \frac{\sigsq}{\sigsqmu}} - \frac{\Rtwobar^2 \none^2}{\ntwo + \frac{\sigsq}{\sigsqmu}}}
\eeqn
}
\subsubsection*{Tree Structure Ratio}

The proposal tree is the same shape as the original tree. Thus we only need to take into account the probabilities of the proposed split and the original split.

\beqn
\frac{\prob{T^*}}{\prob{T}} &=& \frac{\parens{1 - \prob{\text{splitting~} \etaonestar} \parens{1 - \prob{\text{splitting~} \etatwostar}}} \prob{\text{splitting~} \etastar} \prob{\text{rule~} \etastar}}{\parens{1 - \prob{\text{splitting~} \etaone} \parens{1 - \prob{\text{splitting~} \etatwo}}} \prob{\text{splitting~} \eta} \prob{\text{rule~} \eta}}
\eeqn

The one minus probability of splitting will cancel since it's computed based on $\alpha, \beta$ and depth of the leaves which are the same. The probabilities of splitting will cancel based on the same argument. Within the probability of the rule, the number of possible attributes will cancel since it's the same so we really only have to consider:

\beqn
\frac{\prob{T^*}}{\prob{T}} &=& \frac{\nrepstar}{\nrep} \frac{\nadj}{\nadjstar}
\eeqn

Note that this is the inverse of the transition ratio. Thus, only the likelihood ratio needs to be computed to determine $r$ for the change step.

\subsection*{Swap}

Due to the complexity of the bookkeeping, we do not consider this type of step.

%\subsection*{Implementation Details}

%We use what we have above to calculate $\natlog{r}$ for grow, prune, and change steps.

%One thing we would like to estimate is the likelihood of the trees over the lifetime of the Gibbs sampler.


\end{document}